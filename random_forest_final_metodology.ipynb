{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score\n",
    "from scipy.spatial import distance\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo para convertir ticks a segundos\n",
    "def ticks_to_seconds(ticks):\n",
    "    return ticks / 10000000 #10'000'000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método de función para encontrar el valor más cercano en un array\n",
    "Parámetros\n",
    "----------\n",
    "array : array\n",
    "value : valor que se debe de encontrar más cercano\n",
    "\n",
    "Retorno\n",
    "-------\n",
    "Indice en el array y su valor respectivo en el array\n",
    "\"\"\"\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx, array[idx]\n",
    "\n",
    "def find_fpr_and_tpr_given_a_threshold(genuine_scores, impostor_scores, threshold):\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    fprs, tprs, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    idx, value = find_nearest(thresholds, threshold)\n",
    "    return fprs[idx], tprs[idx], value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del método para evaluar el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_Model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy )\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del método para el cálculo del AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método para el cálculo del Area Under the Curve\n",
    "Parámetros\n",
    "----------\n",
    "user_scores : array con los scores o distancias del usuario legítimo\n",
    "impostor_scores : array con los scores o distancias de usuarios ilegítimos\n",
    "\n",
    "Retorno\n",
    "-------\n",
    "AUC: area bajo la curva ROC\n",
    "\"\"\"\n",
    "def evaluate_AUC(genuine_scores, impostor_scores):\n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    auc_score = roc_auc_score(labels, genuine_scores + impostor_scores)\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método para el cálculo del ERR\n",
    "Parámetros\n",
    "----------\n",
    "user_scores : array con los scores o distancias del usuario legítimo\n",
    "impostor_scores : array con los scores o distancias de usuarios ilegítimos\n",
    "\n",
    "Retorno\n",
    "-------\n",
    "Equal Error Rate: punto donde los missrates y los far\n",
    "\"\"\"\n",
    "#Primera forma de hallar el ERR\n",
    "def evaluate_EER(genuine_scores, impostor_scores):\n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    #Variable con los False Negative Rate (FNR) - miss\n",
    "    missrates = 1 - tpr\n",
    "    \n",
    "    #Variable con los False Positive Rate (FPR) - false alarm\n",
    "    farates = fpr\n",
    "    \n",
    "    #Se hallan las distancias entre los FNR y FPR dado cierto umbral\n",
    "    dists = missrates - farates\n",
    "    \n",
    "    #Listas que separan las distancias con los valores \n",
    "    #que estan más cercano al cero tanto superior como inferior\n",
    "    tempList1 = dists[dists >= 0]\n",
    "    tempList2 = dists[dists < 0]\n",
    "    \n",
    "    #Se busca el punto en la curva ROC donde se interceptan geométricamente el FNR y FPR\n",
    "    #El primero que sea el cercano superior al false alarm (>=)\n",
    "    #y aquel que este pegado a este en la curva pero siendo el cercano inferior (<)\n",
    "    # argmin te arroja el indice el item con los menores valores\n",
    "    # argmax te arroja el indice el item con los mayores valores\n",
    "    #idx es una variable que almacena este índice\n",
    "    \n",
    "    #Indice del menor elemento del tempList1 (Lo más pegado al cero superiormente)\n",
    "    idx1 = np.argmin(tempList1)\n",
    "    #Sacar el indice del valor de idx1 (en tempList1), pero en la lista \"dists\"\n",
    "    idx1, = np.where(dists == tempList1[idx1])\n",
    "    \n",
    "    #Indice del mayor elemento del tempList2 (Lo más pegado al cero inferiormente)\n",
    "    idx2 = np.argmax(tempList2)\n",
    "    #Sacar el indice del valor de idx2 (en tempList2), pero en la lista \"dists\"\n",
    "    idx2, = np.where(dists == tempList2[idx2])\n",
    "    \n",
    "    #Se determina es valor de los dos puntos y ponerlo en la variable x e y\n",
    "    x = [missrates[idx1], farates[idx1]]\n",
    "    y = [missrates[idx2], farates[idx2]]\n",
    "\n",
    "    #encuentrar el punto en la línea entre x e y en donde \n",
    "    #los primeros y segundos elementos del vector sean iguales.\n",
    "    #Específicamente, la línea que pasa a través de x e y \n",
    "    #se define como x + a * (y-x) para todo \"a\"\n",
    "    #Si usamos esta formula y lo igualamos, ya q x e y \n",
    "    #deben de coincidir en ese punto de la recta\n",
    "    #  -> x[1] + a*(y[1]-x[1]) = x[2] + a*(y[2]-x[2])\n",
    "    #lo factorizamos para determinar a\n",
    "    #que seria la pendiente de la recta que construiremos\n",
    "    #  -> a = (x[1] - x[2]) / (y[2]-x[2]-y[1]+x[1]) \n",
    "    \n",
    "    a = ( x[0] - x[1] ) / ( y[1] - x[1] - y[0] + x[0] )\n",
    "    eer = x[0] + a * ( y[0] - x[0] )\n",
    "    \n",
    "    return eer\n",
    "\n",
    "\n",
    "#Segunda forma de hallar el EER.\n",
    "def evaluate_EER_Thresh(genuine_scores, impostor_scores):\n",
    "    \n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1]*len(genuine_scores) + [0]*len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    #Se calcula el EER cuando el punto del fpr y del fpr se encuentran\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    \n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    return eer, thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del método para graficar curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCurveROC(genuine_scores, impostor_scores, title = 'Receiver Operating Characteristic'):\n",
    "    \n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    roc_auc = evaluate_AUC(genuine_scores, impostor_scores)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "def plotCurveROC_Threshold(genuine_scores, impostor_scores, threshold_value , threshold_x, threshold_y , color = \"green\" , title = 'Receiver Operating Characteristic'):\n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    roc_auc = evaluate_AUC(genuine_scores, impostor_scores)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.scatter(threshold_x ,threshold_y, color = color)\n",
    "    plt.text(threshold_x + 0.025, threshold_y - 0.05 , threshold_value)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de archivo y eliminación de registros no válidos\n",
    "Se eliminan los registros que NO hayan escrito la palabra greyc laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Se define la ruta donde se encuentra el archivo y se establece la conexión\n",
    "path = \"./data/grey/keystroke.db\"\n",
    "conn = sqlite3.connect(path)\n",
    "\n",
    "#Se hace la lectura y se almacena los datos extraídos en la variable df (\"dataframe\")\n",
    "df = pd.read_sql_query('select * from keystroke_datas', conn, parse_dates=['date'])\n",
    "\n",
    "#Se eliminan los registros de los usuarios que no hallan escrito la palabra 'greyc laboratory'\n",
    "df.drop(df[df['password'] != 'greyc laboratory'].index, inplace = True)\n",
    "\n",
    "#Se hace un cierre de la conexión con la base de datos SQLite\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsualización del dataset original\n",
    " El siguiente dataset contiene las siguientes columnas:\n",
    "  - ppTime: vector de tiempo entre dos teclas presionadas (press - press)\n",
    "  - rrTime: vector de tiempo entre dos teclas soltadas (release - release)\n",
    "  - prTime: vector de tiempo entre una tecla presionada y luego soltada (press - release)\n",
    "  - rpTime: vector de tiempo entre una tecla soltada y luego presionada (release - press)\n",
    "  - vector: este vector concatena todos los vectores anteriores en uno solo\n",
    "  - password: palabra escrita  por el usuario\n",
    "  - user_id: id del usuario\n",
    "  - time_to_type: tiempo que tardo en escribir la palabra\n",
    "  - rawPress: data cruda extraida de las teclas presionadas\n",
    "  - rawRelease: data cruda extraida de las teclas soltadas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ppTime</th>\n",
       "      <th>rrTime</th>\n",
       "      <th>prTime</th>\n",
       "      <th>rpTime</th>\n",
       "      <th>vector</th>\n",
       "      <th>password</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time_to_type</th>\n",
       "      <th>rawPress</th>\n",
       "      <th>rawRelease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2203168 600864 1101584 1602304 801152 2303312...</td>\n",
       "      <td>2203168 901296 500720 2503600 600864 1902736 ...</td>\n",
       "      <td>3204608 1902736 1802592 3204608 2203168 33047...</td>\n",
       "      <td>1201728 -400576 -200288 901296 -801152 901296...</td>\n",
       "      <td>2203168 600864 1101584 1602304 801152 2303312...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:09</td>\n",
       "      <td>30644064</td>\n",
       "      <td>71 633729665463844160\\n82 633729665466047328\\n...</td>\n",
       "      <td>71 633729665464845600\\n82 633729665467048768\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2103024 500720 2703888 1602304 2103024 340489...</td>\n",
       "      <td>1902736 701008 2203168 1802592 2203168 310446...</td>\n",
       "      <td>3104464 1702448 3404896 2503600 3104464 41059...</td>\n",
       "      <td>901296 -500720 1502160 901296 1201728 2403456...</td>\n",
       "      <td>2103024 500720 2703888 1602304 2103024 340489...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:18</td>\n",
       "      <td>33748528</td>\n",
       "      <td>71 633729665547564544\\n82 633729665549667568\\n...</td>\n",
       "      <td>71 633729665548766272\\n82 633729665550669008\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2203168 701008 1402016 1301872 2303312 330475...</td>\n",
       "      <td>2503600 801152 901296 1602304 2203168 3104464...</td>\n",
       "      <td>3304752 1902736 2103024 2303312 3204608 40057...</td>\n",
       "      <td>1402016 -400576 200288 600864 1301872 2403456...</td>\n",
       "      <td>2203168 701008 1402016 1301872 2303312 330475...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:28</td>\n",
       "      <td>29442336</td>\n",
       "      <td>71 633729665651914592\\n82 633729665654117760\\n...</td>\n",
       "      <td>71 633729665652715744\\n82 633729665655219344\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2103024 701008 1902736 1702448 1602304 260374...</td>\n",
       "      <td>2303312 701008 1402016 2002880 1602304 240345...</td>\n",
       "      <td>3304752 1902736 2603744 2703888 2603744 34048...</td>\n",
       "      <td>1101584 -500720 701008 1001440 600864 1602304...</td>\n",
       "      <td>2103024 701008 1902736 1702448 1602304 260374...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:48</td>\n",
       "      <td>31545360</td>\n",
       "      <td>71 633729665853404320\\n82 633729665855507344\\n...</td>\n",
       "      <td>71 633729665854405760\\n82 633729665856709072\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2002880 600864 1201728 1602304 1502160 300432...</td>\n",
       "      <td>2002880 901296 701008 1802592 1502160 2703888...</td>\n",
       "      <td>2904176 1802592 1902736 2503600 2403456 36051...</td>\n",
       "      <td>1101584 -300432 0 901296 600864 2103024 50072...</td>\n",
       "      <td>2002880 600864 1201728 1602304 1502160 300432...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:58</td>\n",
       "      <td>29642624</td>\n",
       "      <td>71 633729665954750048\\n82 633729665956752928\\n...</td>\n",
       "      <td>71 633729665955651344\\n82 633729665957654224\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             ppTime  \\\n",
       "5   6   2203168 600864 1101584 1602304 801152 2303312...   \n",
       "6   7   2103024 500720 2703888 1602304 2103024 340489...   \n",
       "7   8   2203168 701008 1402016 1301872 2303312 330475...   \n",
       "8   9   2103024 701008 1902736 1702448 1602304 260374...   \n",
       "9  10   2002880 600864 1201728 1602304 1502160 300432...   \n",
       "\n",
       "                                              rrTime  \\\n",
       "5   2203168 901296 500720 2503600 600864 1902736 ...   \n",
       "6   1902736 701008 2203168 1802592 2203168 310446...   \n",
       "7   2503600 801152 901296 1602304 2203168 3104464...   \n",
       "8   2303312 701008 1402016 2002880 1602304 240345...   \n",
       "9   2002880 901296 701008 1802592 1502160 2703888...   \n",
       "\n",
       "                                              prTime  \\\n",
       "5   3204608 1902736 1802592 3204608 2203168 33047...   \n",
       "6   3104464 1702448 3404896 2503600 3104464 41059...   \n",
       "7   3304752 1902736 2103024 2303312 3204608 40057...   \n",
       "8   3304752 1902736 2603744 2703888 2603744 34048...   \n",
       "9   2904176 1802592 1902736 2503600 2403456 36051...   \n",
       "\n",
       "                                              rpTime  \\\n",
       "5   1201728 -400576 -200288 901296 -801152 901296...   \n",
       "6   901296 -500720 1502160 901296 1201728 2403456...   \n",
       "7   1402016 -400576 200288 600864 1301872 2403456...   \n",
       "8   1101584 -500720 701008 1001440 600864 1602304...   \n",
       "9   1101584 -300432 0 901296 600864 2103024 50072...   \n",
       "\n",
       "                                              vector          password  \\\n",
       "5   2203168 600864 1101584 1602304 801152 2303312...  greyc laboratory   \n",
       "6   2103024 500720 2703888 1602304 2103024 340489...  greyc laboratory   \n",
       "7   2203168 701008 1402016 1301872 2303312 330475...  greyc laboratory   \n",
       "8   2103024 701008 1902736 1702448 1602304 260374...  greyc laboratory   \n",
       "9   2002880 600864 1201728 1602304 1502160 300432...  greyc laboratory   \n",
       "\n",
       "   user_id                date  time_to_type  \\\n",
       "5        1 2009-03-18 08:49:09      30644064   \n",
       "6        1 2009-03-18 08:49:18      33748528   \n",
       "7        1 2009-03-18 08:49:28      29442336   \n",
       "8        1 2009-03-18 08:49:48      31545360   \n",
       "9        1 2009-03-18 08:49:58      29642624   \n",
       "\n",
       "                                            rawPress  \\\n",
       "5  71 633729665463844160\\n82 633729665466047328\\n...   \n",
       "6  71 633729665547564544\\n82 633729665549667568\\n...   \n",
       "7  71 633729665651914592\\n82 633729665654117760\\n...   \n",
       "8  71 633729665853404320\\n82 633729665855507344\\n...   \n",
       "9  71 633729665954750048\\n82 633729665956752928\\n...   \n",
       "\n",
       "                                          rawRelease  \n",
       "5  71 633729665464845600\\n82 633729665467048768\\n...  \n",
       "6  71 633729665548766272\\n82 633729665550669008\\n...  \n",
       "7  71 633729665652715744\\n82 633729665655219344\\n...  \n",
       "8  71 633729665854405760\\n82 633729665856709072\\n...  \n",
       "9  71 633729665955651344\\n82 633729665957654224\\n...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de vectores de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Variable temporal para almacenar los items de la columna vector\n",
    "#ya que no se puede trabajar directamente con ese formato\n",
    "tempData = []\n",
    "\n",
    "#Variable con la cantidad de registros totales de la bd\n",
    "n_data_rows = df.shape[0]\n",
    "\n",
    "#Variable que tendrá la lista de columnas del dataframe\n",
    "columns = [\"user_id\"]   \n",
    "\n",
    "#Como existen en total 60 features de tiempo por usuario, se generará \n",
    "#los nombres de las columnas siguiento el siguiente formato \n",
    "#=> 'ft_'   +  posición del feature en el vector\n",
    "for i in range(60):\n",
    "    columns.append(\"ft_\" + str(i+1))\n",
    "\n",
    "#Por cada registro que existe en la bd se aplica lo siguente\n",
    "for i in range(n_data_rows):\n",
    "    \n",
    "    #Se extrae el usuario de ese registro\n",
    "    user_id = [df.iloc[i][\"user_id\"]]\n",
    "    #Se extrae el tiempo de tecleo\n",
    "    time_to_type = [df.iloc[i][\"time_to_type\"]]\n",
    "    \n",
    "    #Se crea el vector de tiempo\n",
    "    vector = df.iloc[i][\"vector\"].split()      \n",
    " \n",
    "    #Se verifica que la integridad del vector este OK,\n",
    "    #es decir que tenga una longitud exacta de 60 items\n",
    "    if(len(vector) == 60 ):\n",
    "        #Se aprega el registro a la variable temporarl tempData si cumple con la condición de integridad\n",
    "        tempData.append(user_id  + list(map(int, vector)))\n",
    "\n",
    "#Se crea el dataframe y se asigna a la variable df\n",
    "df = pd.DataFrame(tempData, columns = columns)\n",
    "\n",
    "#Conversion de tick a segundos \n",
    "features = df.columns[1:61]\n",
    "for i in range(len(features)):\n",
    "    col = features[i]\n",
    "    df[col] = df[col].apply(lambda x: ticks_to_seconds(x))\n",
    "\n",
    "#Se liberan recursos de la variable\n",
    "tempData.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsualización de dataset procesado\n",
    "Por cada registro, se tienen las siguientes columnas\n",
    " - Los features entre el 1 y 12 corresponden al vector de tiempo ppTime\n",
    " - Los features entre el 13 y 25 corresponden al vector de tiempo rrTime\n",
    " - Los features entre el 26 y 37 corresponden al vector de tiempo prTime\n",
    " - Los features entre el 38 y 60 corresponden al vector de tiempo rpTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.210302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.210302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.390562</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.260374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.240346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.390562</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.220317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id      ft_1      ft_2      ft_3      ft_4      ft_5      ft_6  \\\n",
       "0        1  0.220317  0.060086  0.110158  0.160230  0.080115  0.230331   \n",
       "1        1  0.210302  0.050072  0.270389  0.160230  0.210302  0.340490   \n",
       "2        1  0.220317  0.070101  0.140202  0.130187  0.230331  0.330475   \n",
       "3        1  0.210302  0.070101  0.190274  0.170245  0.160230  0.260374   \n",
       "4        1  0.200288  0.060086  0.120173  0.160230  0.150216  0.300432   \n",
       "\n",
       "       ft_7      ft_8      ft_9  ...     ft_51     ft_52     ft_53     ft_54  \\\n",
       "0  0.100144  0.260374  0.140202  ...  0.330475  0.200288  0.360518  0.200288   \n",
       "1  0.140202  0.260374  0.140202  ...  0.410590  0.230331  0.350504  0.210302   \n",
       "2  0.090130  0.300432  0.150216  ...  0.400576  0.190274  0.390562  0.220317   \n",
       "3  0.150216  0.300432  0.150216  ...  0.340490  0.270389  0.400576  0.220317   \n",
       "4  0.110158  0.290418  0.160230  ...  0.360518  0.220317  0.390562  0.230331   \n",
       "\n",
       "      ft_55     ft_56     ft_57     ft_58     ft_59     ft_60  \n",
       "0  0.280403  0.240346  0.290418  0.240346  0.230331  0.210302  \n",
       "1  0.220317  0.260374  0.280403  0.260374  0.310446  0.210302  \n",
       "2  0.230331  0.310446  0.260374  0.220317  0.220317  0.260374  \n",
       "3  0.230331  0.240346  0.310446  0.210302  0.290418  0.240346  \n",
       "4  0.260374  0.310446  0.260374  0.190274  0.250360  0.220317  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación de la data de entrenamiento y de prueba\n",
    "Se toma de forma aleatoria el 80% de los registros de cada usuario para considerarlos como data de entrenamiento, el 10%  para la data de desarrollo del umbral y el 10 % restante para la data de prueba\n",
    "\n",
    "\n",
    "La función train_test_split cuando existe un grupo impar, siempre el último subgrupo recibe el elemento extra.\n",
    "Se trató de redondear el 0.80 del parámetro **train_size** debido a que cuando se trabaja con esta cantidad, arrojaba una mayor cantidad de splits con subdatasets de dev y de test desiguales. Aproximandamente **73**\n",
    "![Resultados usando una proporcion de 80](./img/Proportion%20split%2080.png)\n",
    "\n",
    "Poner 0.84 en el parámetro **train_size** permite tener menores grupos de subdatasets de dev y de test desiguales. En este solo se obtienen **4** de este tipo.\n",
    "> Se debe de mantener que el dataset de dev sea lo más similar al de test.\n",
    "\n",
    "[Link de fuente](https://cs230.stanford.edu/blog/split/)\n",
    "\n",
    "![Resultados usando una proporcion de 84](./img/Proportion%20split%2084.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable que contiene la lista de todos los usuarios de la bd\n",
    "subjects = df[\"user_id\"].unique()\n",
    "\n",
    "#Variable del dataset de train 80%\n",
    "train_users = []\n",
    "\n",
    "#Variable del dataset de dev (desarrollo) para el calculo del umbral 10%\n",
    "dev_users = []\n",
    "\n",
    "#Variable del dataset de test 10%\n",
    "test_users = []\n",
    "\n",
    "#Separar el df en 80 / 10 / 20 respectivamente y asignarlo a sus \n",
    "for subject in subjects:\n",
    "    current_user_data = df.loc[df.user_id == subject, :]\n",
    "            \n",
    "    #impostor_data = df.loc[df.user_id != subject, :]\n",
    "    \n",
    "    #Caso especial de una proporcion de 60/20/20 cuando el usuario tiene solo 5 registros\n",
    "    #Para no eliminar ese registro y no lanze error \n",
    "    #Donde quedaría asi 5 -> 3 / 1 / 1\n",
    "\n",
    "    if len(current_user_data) == 5:\n",
    "        train, dev = train_test_split(current_user_data, train_size = 0.6, random_state=43, shuffle=True)\n",
    "        dev , test = train_test_split(dev, train_size = 0.5, random_state=43, shuffle=True)\n",
    "    \n",
    "    #Caso contrario se respeta la proporcion de 80/10/10 establecida antes\n",
    "    else:\n",
    "        train, dev = train_test_split(current_user_data, train_size = 0.80, random_state=43, shuffle=True)\n",
    "        dev , test = train_test_split(dev, train_size = 0.5, random_state=43, shuffle=True)\n",
    "        \n",
    "    #Se agregan a los 3 datasets los splits calculados aleatoriamente\n",
    "    train_users.append(train)\n",
    "    dev_users.append(dev)\n",
    "    test_users.append(test)\n",
    "\n",
    "#Se convierte los arrays en dataframes manipulables\n",
    "train_users = pd.concat(train_users)\n",
    "dev_users = pd.concat(dev_users)\n",
    "test_users = pd.concat(test_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsualización del dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.160230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.430619</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>1</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.160230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>1</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.190274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.170245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7483</th>\n",
       "      <td>133</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.640922</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.370533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>133</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.390562</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470677</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.771109</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.390562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>133</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.520749</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.350504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>133</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.560806</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640922</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.510734</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.380547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7312</th>\n",
       "      <td>133</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.550792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5991 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id      ft_1      ft_2      ft_3      ft_4      ft_5      ft_6  \\\n",
       "4797        1  0.210302  0.070101  0.260374  0.100144  0.100144  0.200288   \n",
       "12          1  0.240346  0.060086  0.140202  0.160230  0.080115  0.210302   \n",
       "3959        1  0.190274  0.070101  0.100144  0.080115  0.100144  0.190274   \n",
       "6799        1  0.200288  0.070101  0.100144  0.130187  0.100144  0.210302   \n",
       "2222        1  0.210302  0.070101  0.090130  0.120173  0.070101  0.240346   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "7483      133  0.330475  0.240346  0.230331  0.190274  0.170245  0.220317   \n",
       "7480      133  0.190274  0.200288  0.210302  0.210302  0.170245  0.390562   \n",
       "7481      133  0.220317  0.180259  0.220317  0.160230  0.140202  0.260374   \n",
       "7308      133  0.190274  0.200288  0.190274  0.200288  0.190274  0.560806   \n",
       "7312      133  0.200288  0.210302  0.300432  0.260374  0.150216  0.190274   \n",
       "\n",
       "          ft_7      ft_8      ft_9  ...     ft_51     ft_52     ft_53  \\\n",
       "4797  0.050072  0.240346  0.140202  ...  0.300432  0.170245  0.360518   \n",
       "12    0.120173  0.300432  0.170245  ...  0.320461  0.230331  0.430619   \n",
       "3959  0.050072  0.260374  0.090130  ...  0.260374  0.170245  0.340490   \n",
       "6799  0.170245  0.160230  0.290418  ...  0.290418  0.280403  0.240346   \n",
       "2222  0.100144  0.210302  0.140202  ...  0.340490  0.190274  0.330475   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7483  0.210302  0.190274  0.240346  ...  0.340490  0.300432  0.310446   \n",
       "7480  0.190274  0.230331  0.220317  ...  0.470677  0.280403  0.330475   \n",
       "7481  0.220317  0.210302  0.160230  ...  0.380547  0.320461  0.300432   \n",
       "7308  0.180259  0.120173  0.190274  ...  0.640922  0.260374  0.200288   \n",
       "7312  0.160230  0.180259  0.210302  ...  0.300432  0.270389  0.270389   \n",
       "\n",
       "         ft_54     ft_55     ft_56     ft_57     ft_58     ft_59     ft_60  \n",
       "4797  0.220317  0.270389  0.160230  0.220317  0.170245  0.340490  0.160230  \n",
       "12    0.250360  0.260374  0.270389  0.270389  0.210302  0.260374  0.220317  \n",
       "3959  0.160230  0.290418  0.240346  0.210302  0.140202  0.250360  0.160230  \n",
       "6799  0.400576  0.330475  0.260374  0.260374  0.180259  0.270389  0.190274  \n",
       "2222  0.210302  0.310446  0.270389  0.250360  0.160230  0.300432  0.170245  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7483  0.330475  0.640922  0.310446  0.330475  0.190274  0.240346  0.370533  \n",
       "7480  0.310446  0.280403  0.320461  0.771109  0.340490  0.250360  0.390562  \n",
       "7481  0.280403  0.290418  0.280403  0.520749  0.260374  0.260374  0.350504  \n",
       "7308  0.310446  0.330475  0.360518  0.510734  0.260374  0.300432  0.380547  \n",
       "7312  0.340490  0.440634  0.360518  0.410590  0.260374  0.310446  0.550792  \n",
       "\n",
       "[5991 rows x 61 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsualización del dataset de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.040058</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.210302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>1</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.230331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.250360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.250360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.210302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>132</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.290418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7359</th>\n",
       "      <td>132</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.550792</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>1.031483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7140</th>\n",
       "      <td>132</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450648</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.690994</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.410590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7314</th>\n",
       "      <td>133</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.560806</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.360518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>133</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.600864</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.951368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id      ft_1      ft_2      ft_3      ft_4      ft_5      ft_6  \\\n",
       "11          1  0.220317  0.040058  0.270389  0.180259  0.170245  0.290418   \n",
       "4789        1  0.190274  0.070101  0.150216  0.110158  0.070101  0.240346   \n",
       "2323        1  0.220317  0.070101  0.130187  0.110158  0.080115  0.230331   \n",
       "8           1  0.210302  0.060086  0.120173  0.170245  0.310446  0.240346   \n",
       "0           1  0.220317  0.060086  0.110158  0.160230  0.080115  0.230331   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "7148      132  0.210302  0.150216  0.180259  0.160230  0.160230  0.290418   \n",
       "7359      132  0.210302  0.120173  0.160230  0.160230  0.170245  0.260374   \n",
       "7140      132  0.230331  0.150216  0.220317  0.180259  0.200288  0.380547   \n",
       "7314      133  0.190274  0.210302  0.560806  0.280403  0.130187  0.190274   \n",
       "7487      133  0.170245  0.190274  0.190274  0.210302  0.140202  0.220317   \n",
       "\n",
       "          ft_7      ft_8      ft_9  ...     ft_51     ft_52     ft_53  \\\n",
       "11    0.130187  0.310446  0.120173  ...  0.360518  0.230331  0.410590   \n",
       "4789  0.100144  0.210302  0.120173  ...  0.360518  0.220317  0.330475   \n",
       "2323  0.050072  0.250360  0.150216  ...  0.330475  0.180259  0.370533   \n",
       "8     0.140202  0.350504  0.150216  ...  0.320461  0.250360  0.440634   \n",
       "0     0.100144  0.260374  0.140202  ...  0.330475  0.200288  0.360518   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7148  0.160230  0.140202  0.190274  ...  0.370533  0.260374  0.220317   \n",
       "7359  0.140202  0.180259  0.140202  ...  0.340490  0.240346  0.240346   \n",
       "7140  0.140202  0.190274  0.170245  ...  0.450648  0.250360  0.280403   \n",
       "7314  0.140202  0.170245  0.210302  ...  0.300432  0.260374  0.280403   \n",
       "7487  0.230331  0.140202  0.220317  ...  0.310446  0.350504  0.260374   \n",
       "\n",
       "         ft_54     ft_55     ft_56     ft_57     ft_58     ft_59     ft_60  \n",
       "11    0.220317  0.240346  0.250360  0.260374  0.220317  0.270389  0.210302  \n",
       "4789  0.210302  0.330475  0.250360  0.240346  0.170245  0.300432  0.230331  \n",
       "2323  0.230331  0.300432  0.290418  0.270389  0.220317  0.270389  0.250360  \n",
       "8     0.220317  0.240346  0.250360  0.270389  0.180259  0.260374  0.250360  \n",
       "0     0.200288  0.280403  0.240346  0.290418  0.240346  0.230331  0.210302  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7148  0.260374  0.330475  0.230331  0.120173  0.380547  0.360518  0.290418  \n",
       "7359  0.220317  0.340490  0.240346  0.140202  0.550792  0.360518  1.031483  \n",
       "7140  0.250360  0.370533  0.270389  0.190274  0.690994  0.300432  0.410590  \n",
       "7314  0.330475  0.310446  0.290418  0.360518  0.240346  0.230331  0.360518  \n",
       "7487  0.340490  0.280403  0.300432  0.600864  0.220317  0.290418  0.951368  \n",
       "\n",
       "[742 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsualización del dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6795</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.040058</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.230331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>1</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.150216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>1</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.160230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.420605</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.230331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.190274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>132</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.530763</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.340490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>132</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.430619</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.240346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>133</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.480691</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.580835</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.420605</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.390562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>133</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.500720</td>\n",
       "      <td>0.430619</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.410590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>133</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.420605</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.460662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id      ft_1      ft_2      ft_3      ft_4      ft_5      ft_6  \\\n",
       "6795        1  0.250360  0.040058  0.190274  0.120173  0.070101  0.220317   \n",
       "3954        1  0.170245  0.070101  0.110158  0.090130  0.070101  0.200288   \n",
       "6802        1  0.190274  0.070101  0.150216  0.110158  0.090130  0.220317   \n",
       "405         1  0.160230  0.090130  0.090130  0.170245  0.090130  0.180259   \n",
       "4791        1  0.250360  0.080115  0.210302  0.120173  0.100144  0.210302   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "6751      132  0.200288  0.140202  0.160230  0.180259  0.160230  0.280403   \n",
       "6754      132  0.210302  0.170245  0.190274  0.140202  0.170245  0.280403   \n",
       "7477      133  0.210302  0.290418  0.350504  0.380547  0.120173  0.210302   \n",
       "7313      133  0.220317  0.180259  0.170245  0.120173  0.190274  0.190274   \n",
       "7318      133  0.190274  0.190274  0.230331  0.170245  0.170245  0.200288   \n",
       "\n",
       "          ft_7      ft_8      ft_9  ...     ft_51     ft_52     ft_53  \\\n",
       "6795  0.130187  0.230331  0.280403  ...  0.310446  0.260374  0.340490   \n",
       "3954  0.050072  0.230331  0.090130  ...  0.280403  0.160230  0.340490   \n",
       "6802  0.120173  0.190274  0.260374  ...  0.320461  0.240346  0.290418   \n",
       "405   0.120173  0.260374  0.140202  ...  0.300432  0.230331  0.420605   \n",
       "4791  0.120173  0.240346  0.180259  ...  0.300432  0.240346  0.380547   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6751  0.160230  0.150216  0.210302  ...  0.360518  0.280403  0.220317   \n",
       "6754  0.190274  0.160230  0.200288  ...  0.380547  0.280403  0.260374   \n",
       "7477  0.480691  0.140202  0.260374  ...  0.330475  0.580835  0.260374   \n",
       "7313  0.210302  0.140202  0.400576  ...  0.330475  0.300432  0.190274   \n",
       "7318  0.160230  0.170245  0.300432  ...  0.310446  0.280403  0.280403   \n",
       "\n",
       "         ft_54     ft_55     ft_56     ft_57     ft_58     ft_59     ft_60  \n",
       "6795  0.370533  0.320461  0.240346  0.290418  0.190274  0.320461  0.230331  \n",
       "3954  0.170245  0.280403  0.220317  0.220317  0.160230  0.260374  0.150216  \n",
       "6802  0.330475  0.290418  0.260374  0.230331  0.110158  0.280403  0.160230  \n",
       "405   0.240346  0.310446  0.260374  0.250360  0.240346  0.250360  0.230331  \n",
       "4791  0.250360  0.310446  0.280403  0.280403  0.170245  0.350504  0.190274  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6751  0.290418  0.330475  0.260374  0.170245  0.530763  0.370533  0.340490  \n",
       "6754  0.290418  0.360518  0.240346  0.190274  0.430619  0.350504  0.240346  \n",
       "7477  0.380547  0.240346  0.350504  0.420605  0.290418  0.280403  0.390562  \n",
       "7313  0.500720  0.430619  0.400576  0.380547  0.270389  0.320461  0.410590  \n",
       "7318  0.410590  0.370533  0.420605  0.360518  0.270389  0.330475  0.460662  \n",
       "\n",
       "[815 rows x 61 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de las probablidades con los registros de test\n",
    "\n",
    "![Calculo de distancias](./img/Calculo%20de%20distancias.png)\n",
    "\n",
    "### Ejemplo del usuario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de los datos a usar para el usuario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aca obtenemos el X_train, y_train del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos una copia temporal del dataset de entrenamiento\n",
    "temp1 = train_users.copy()\n",
    "\n",
    "#Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "temp1[\"user_id\"] = temp1[\"user_id\"].mask(temp1[\"user_id\"] != 1, 0)\n",
    "\n",
    "#Obtenemos los registros considerados genuinos del entrenamiento\n",
    "genuine_data = temp1.loc[temp1.user_id == 1, :]\n",
    "\n",
    "#Obtenemos los registros considerados impostores del entrenamiento.\n",
    "#Este debe de ser del mismo tamaño que de los registros genuinos\n",
    "impostor_data = temp1.loc[temp1.user_id != 1, :].sample(n= genuine_data.shape[0], random_state=43)\n",
    "\n",
    "#Lo unimos los dos anteriores en un solo dataset de entrenamiento del modelo del usuario 1\n",
    "train = pd.concat([genuine_data, impostor_data])\n",
    "\n",
    "#Obtenemos el X_train\n",
    "X_train = train.loc[:, \"ft_1\":\"ft_60\" ]\n",
    "\n",
    "#Obtenemos el y_train\n",
    "y_train = train.loc[:, \"user_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtenemos el X_dev , y_dev, X_test y y_test del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos una copia temporal del dataset de desarrollo\n",
    "temp2 = dev_users.copy()\n",
    "\n",
    "#Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "temp2[\"user_id\"] = temp2[\"user_id\"].mask(temp2[\"user_id\"] != 1, 0)\n",
    "\n",
    "#df.sample(frac=0.5, replace=True, random_state=1)\n",
    "X_dev = temp2.loc[:, \"ft_1\":\"ft_60\"]\n",
    "y_dev = temp2.loc[:, \"user_id\"]\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "#Generamos una copia temporal del dataset de test\n",
    "temp3 = test_users.copy()\n",
    "\n",
    "#Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "temp3[\"user_id\"] = temp3[\"user_id\"].mask(temp3[\"user_id\"] != 1, 0)\n",
    "\n",
    "X_test = temp3.loc[:, \"ft_1\":\"ft_60\"]\n",
    "y_test = temp3.loc[:, \"user_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos la busqueda de los mejores hiperparámetros\n",
    "\n",
    "Comenzamos con un Random Search Cross Validation para deliminar el universo de busqueda de los parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 43,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#Creamos un modelo Random Forest\n",
    "rf = RandomForestClassifier(random_state = 43)\n",
    "\n",
    "#Mostramos parametros por default\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 110}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 300 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=43, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "search = rf_random.fit(X_train,y_train)\n",
    "\n",
    "#Mejores mejores parametros\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con los parámetros por default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9730458221024259\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 43)\n",
    "base_model.fit(X_train,y_train)\n",
    "base_accuracy = evaluate_Model(base_model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con los parámetros encontrados por el Random Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9784366576819407\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate_Model(best_random, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos uso de grid search para tener mejores pámetros, al rededor de los parámetros encontrados en el random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 700}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [20 ,30,40, 50, 60, None],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'n_estimators': [500, 600, 700]\n",
    "}\n",
    "\n",
    "#Creamos un modelo Random Forest\n",
    "rf = RandomForestClassifier(random_state = 43)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con los parámetros encontrados por el Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9797843665768194\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate_Model(best_grid, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo con mejores hiperparametros  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=600,\n",
       "                       n_jobs=None, oob_score=False, random_state=43, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos el modelo Random Forest\n",
    "clf = RandomForestClassifier(random_state = 43, max_depth= 20, \n",
    "                             max_features= 'auto',  min_samples_leaf= 1,\n",
    "                               min_samples_split= 2, n_estimators= 600)\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos las predicciones\n",
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado con el subdataset de prueba del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977088948787062\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de las probabilidades de cada registro usando el modelo del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probImpos</th>\n",
       "      <th>probLegi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068333</td>\n",
       "      <td>0.931667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.996667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0.948333</td>\n",
       "      <td>0.051667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.028333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.038333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     probImpos  probLegi\n",
       "0     0.025000  0.975000\n",
       "1     0.068333  0.931667\n",
       "2     0.003333  0.996667\n",
       "3     0.246667  0.753333\n",
       "4     0.100000  0.900000\n",
       "..         ...       ...\n",
       "810   0.948333  0.051667\n",
       "811   0.940000  0.060000\n",
       "812   0.971667  0.028333\n",
       "813   0.961667  0.038333\n",
       "814   0.985000  0.015000\n",
       "\n",
       "[815 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Con la función predict_proba obtenemos las probabilidades para cada clase.\n",
    "#En el primero, obtenemos la probalidad de que sea un registro de un usuario impostor\n",
    "#En el otro, obtenemos la probalidad de que el registro pertenesca al usuario 1 (legitimo)\n",
    "y_prob = clf.predict_proba(X_test)\n",
    "y_prob = pd.DataFrame(y_prob, columns = [\"probImpos\", \"probLegi\"])\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable donde se almacenará toda la informacion calculada del usuario 1 \n",
    "user_1_evaluation_dev = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "#Para cada registro del subdataset de test\n",
    "for index, row in dev_users.iterrows():\n",
    "    \n",
    "    temp_obj = {}\n",
    "    \n",
    "    #user id del registro actual del subdataset de test\n",
    "    current_user_id = row[0]\n",
    "    \n",
    "    #Vector de tiempo del registro actual del subdataset de test\n",
    "    current_data = row[1:]\n",
    "    \n",
    "    #Actual modelo del usuario a evaluar\n",
    "    temp_obj[\"user_model\"] = 1\n",
    "\n",
    "    #user id del registro actual\n",
    "    temp_obj[\"user_id\"] = current_user_id\n",
    "    \n",
    "    #Puntaje o score del modelo\n",
    "    temp_obj[\"score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "    #Normalizacion del score\n",
    "    temp_obj[\"std_score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "    \n",
    "    #Variable que indica si el registro deberia de ser clasificado como geniono o impostor\n",
    "    if current_user_id == 1:\n",
    "        temp_obj[\"y_test\"] = \"genuine\"\n",
    "    else:\n",
    "        temp_obj[\"y_test\"] = \"impostor\"\n",
    "    \n",
    "    user_1_evaluation_dev.append(temp_obj)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "user_1_evaluation_dev = pd.DataFrame(user_1_evaluation_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntaje de los registros del subdataset de desarrollo usando el modelo del usuario 1\n",
    " - **user_model:** modelo del usuario empleado para sacar el score\n",
    " - **user_id:** usuario del registro evaluado\n",
    " - **score:** puntuación que le dió el modelo\n",
    " - **std_score:** puntuación normalizada\n",
    " - **y_test:** cuando el user_model y user_id **(1)** coinciden, entonces se usó un registro de usuario considerado genuino; caso contrario, es de un impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_model  user_id     score  std_score    y_test\n",
       "0             1      1.0  0.975000   0.975000   genuine\n",
       "1             1      1.0  0.931667   0.931667   genuine\n",
       "2             1      1.0  0.996667   0.996667   genuine\n",
       "3             1      1.0  0.753333   0.753333   genuine\n",
       "4             1      1.0  0.900000   0.900000   genuine\n",
       "..          ...      ...       ...        ...       ...\n",
       "737           1    132.0  0.001667   0.001667  impostor\n",
       "738           1    132.0  0.056667   0.056667  impostor\n",
       "739           1    132.0  0.023333   0.023333  impostor\n",
       "740           1    133.0  0.041667   0.041667  impostor\n",
       "741           1    133.0  0.115000   0.115000  impostor\n",
       "\n",
       "[742 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_1_evaluation_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo usando los modelos de todos los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_evaluation_dev = []\n",
    "\n",
    "#Se hace el cálculo para cada usuario\n",
    "for subject in subjects:\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    #Generamos una copia temporal del dataset de entrenamiento\n",
    "    temp1 = train_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al sujeto actual por 0\n",
    "    temp1[\"user_id\"] = temp1[\"user_id\"].mask(temp1[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #Obtenemos los registros considerados genuinos del entrenamiento\n",
    "    genuine_data = temp1.loc[temp1.user_id == subject, :]\n",
    "\n",
    "    #Obtenemos los registros considerados impostores del entrenamiento.\n",
    "    #Este debe de ser del mismo tamaño que de los registros genuinos\n",
    "    impostor_data = temp1.loc[temp1.user_id != subject, :].sample(n= genuine_data.shape[0], random_state=43)\n",
    "\n",
    "    #Unimos los dos anteriores variables en un solo dataset de entrenamiento del modelo\n",
    "    train = pd.concat([genuine_data, impostor_data])\n",
    "\n",
    "    #Obtenemos el X_train\n",
    "    X_train = train.loc[:, \"ft_1\":\"ft_60\" ]\n",
    "\n",
    "    #Obtenemos el y_train\n",
    "    y_train = train.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Generamos una copia temporal del dataset de desarrollo\n",
    "    temp2 = dev_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp2[\"user_id\"] = temp2[\"user_id\"].mask(temp2[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #df.sample(frac=0.5, replace=True, random_state=1)\n",
    "    X_dev = temp2.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_dev = temp2.loc[:, \"user_id\"]\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "\n",
    "    #Generamos una copia temporal del dataset de test\n",
    "    temp3 = test_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp3[\"user_id\"] = temp3[\"user_id\"].mask(temp3[\"user_id\"] != subject, 0)\n",
    "\n",
    "    X_test = temp3.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_test = temp3.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Entrenamos el modelo Random Forest\n",
    "    \n",
    "    \n",
    "    clf = RandomForestClassifier(random_state = 43, max_depth= 20, \n",
    "                                 max_features= 'auto',  min_samples_leaf= 1,\n",
    "                                   min_samples_split= 3, n_estimators= 700)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #clf = RandomForestClassifier(random_state = 43)\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Obtenemos probabilidades de cada registro del dataset de test\n",
    "    y_prob = clf.predict_proba(X_dev)\n",
    "    y_prob = pd.DataFrame(y_prob, columns = [\"probImpos\", \"probLegi\"])\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    #Para cada registro del subdataset de test\n",
    "    for index, row in dev_users.iterrows():\n",
    "\n",
    "        temp_obj = {}\n",
    "\n",
    "        #user id del registro actual del subdataset de test\n",
    "        current_user_id = row[0]\n",
    "\n",
    "        #Vector de tiempo del registro actual del subdataset de test\n",
    "        current_data = row[1:]\n",
    "\n",
    "        #Actual modelo del usuario a evaluar\n",
    "        temp_obj[\"user_model\"] = subject\n",
    "\n",
    "        #user id del registro actual\n",
    "        temp_obj[\"user_id\"] = current_user_id\n",
    "\n",
    "        #Puntaje o score del modelo\n",
    "        temp_obj[\"score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Normalizacion del score\n",
    "        temp_obj[\"std_score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Variable que indica si el registro deberia de ser clasificado como genuino o impostor\n",
    "        if current_user_id == subject:\n",
    "            temp_obj[\"y_test\"] = \"genuine\"\n",
    "        else:\n",
    "            temp_obj[\"y_test\"] = \"impostor\"\n",
    "\n",
    "        users_evaluation_dev.append(temp_obj)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "users_evaluation_dev = pd.DataFrame(users_evaluation_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntaje de los registros del subdataset de test usando todos los modelos\n",
    " - **user_model:** modelo del usuario empleado para sacar el score\n",
    " - **user_id:** usuario del registro evaluado\n",
    " - **score:** puntuación que le dió el modelo\n",
    " - **std_score:** puntuación normalizada\n",
    " - **y_test:** cuando el user_model y user_id coinciden, entonces se usó un registro de usuario considerado genuino; caso contrario, es de un impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.558714</td>\n",
       "      <td>0.558714</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940119</td>\n",
       "      <td>0.940119</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826881</td>\n",
       "      <td>0.826881</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853810</td>\n",
       "      <td>0.853810</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98681</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.040476</td>\n",
       "      <td>0.040476</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98682</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.429643</td>\n",
       "      <td>0.429643</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98683</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.587976</td>\n",
       "      <td>0.587976</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98684</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.808929</td>\n",
       "      <td>0.808929</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98685</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98686 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_model  user_id     score  std_score    y_test\n",
       "0               1      1.0  0.558714   0.558714   genuine\n",
       "1               1      1.0  0.940119   0.940119   genuine\n",
       "2               1      1.0  0.995000   0.995000   genuine\n",
       "3               1      1.0  0.826881   0.826881   genuine\n",
       "4               1      1.0  0.853810   0.853810   genuine\n",
       "...           ...      ...       ...        ...       ...\n",
       "98681         133    132.0  0.040476   0.040476  impostor\n",
       "98682         133    132.0  0.429643   0.429643  impostor\n",
       "98683         133    132.0  0.587976   0.587976  impostor\n",
       "98684         133    133.0  0.808929   0.808929   genuine\n",
       "98685         133    133.0  0.976190   0.976190   genuine\n",
       "\n",
       "[98686 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_evaluation_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como genuinos por los modelos\n",
    "genuine_scores_dev = list(users_evaluation_dev.loc[users_evaluation_dev.y_test == \"genuine\", \"score\"])\n",
    "\n",
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como impostores por los modelos\n",
    "impostor_scores_dev = list(users_evaluation_dev.loc[users_evaluation_dev.y_test == \"impostor\", \"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo del umbral de decisión con el subdataset de DESARROLLO\n",
    "\n",
    "Buscamos el punto en donde los falsos negativos y los falsos positivos son iguales en los modelos de manera global\n",
    "![Calculo de umbral](./img/Calculo%20del%20umbral.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculo del ERR y del umbral de decisión global\n",
    "err_dev, thresh_dev = evaluate_EER_Thresh(genuine_scores_dev, impostor_scores_dev)\n",
    "\n",
    "\n",
    "#Ploteamos la curva ROC de los umbrales\n",
    "plotCurveROC ( genuine_scores_dev, impostor_scores_dev, title = \"ROC del modelo Random Forest con el dataset de validación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umbral de decisión global hallado (en formato score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.54190476)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respectiva tasa de error que nos daria el umbral de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04447439353099554"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.558714</td>\n",
       "      <td>0.558714</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940119</td>\n",
       "      <td>0.940119</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826881</td>\n",
       "      <td>0.826881</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853810</td>\n",
       "      <td>0.853810</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98681</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.040476</td>\n",
       "      <td>0.040476</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98682</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.429643</td>\n",
       "      <td>0.429643</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98683</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.587976</td>\n",
       "      <td>0.587976</td>\n",
       "      <td>impostor</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98684</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.808929</td>\n",
       "      <td>0.808929</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98685</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98686 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_model  user_id     score  std_score    y_test    y_pred\n",
       "0               1      1.0  0.558714   0.558714   genuine   genuine\n",
       "1               1      1.0  0.940119   0.940119   genuine   genuine\n",
       "2               1      1.0  0.995000   0.995000   genuine   genuine\n",
       "3               1      1.0  0.826881   0.826881   genuine   genuine\n",
       "4               1      1.0  0.853810   0.853810   genuine   genuine\n",
       "...           ...      ...       ...        ...       ...       ...\n",
       "98681         133    132.0  0.040476   0.040476  impostor  impostor\n",
       "98682         133    132.0  0.429643   0.429643  impostor  impostor\n",
       "98683         133    132.0  0.587976   0.587976  impostor   genuine\n",
       "98684         133    133.0  0.808929   0.808929   genuine   genuine\n",
       "98685         133    133.0  0.976190   0.976190   genuine   genuine\n",
       "\n",
       "[98686 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_evaluation_dev['y_pred'] = np.where(users_evaluation_dev['score'] >= thresh_dev, 'genuine', 'impostor')\n",
    "\n",
    "users_evaluation_dev.to_excel(\"./output/outputPredRandomForestDev.xlsx\")\n",
    "\n",
    "#Presentamos el calculo de resultados\n",
    "users_evaluation_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los y_test y y_pred de nuestros resultados\n",
    "y_test_dev = users_evaluation_dev.loc[:, \"y_test\"]\n",
    "y_pred_dev = users_evaluation_dev.loc[:, \"y_pred\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión del umbral hallado con el subdataset de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555357396185883"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_dev, y_pred_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del umbral usando el subdataset de PRUEBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_evaluation_test = []\n",
    "\n",
    "#Se hace el cálculo para cada usuario\n",
    "for subject in subjects:\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    #Generamos una copia temporal del dataset de entrenamiento\n",
    "    temp1 = train_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al sujeto actual por 0\n",
    "    temp1[\"user_id\"] = temp1[\"user_id\"].mask(temp1[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #Obtenemos los registros considerados genuinos del entrenamiento\n",
    "    genuine_data = temp1.loc[temp1.user_id == subject, :]\n",
    "\n",
    "    #Obtenemos los registros considerados impostores del entrenamiento.\n",
    "    #Este debe de ser del mismo tamaño que de los registros genuinos\n",
    "    impostor_data = temp1.loc[temp1.user_id != subject, :].sample(n= genuine_data.shape[0], random_state=43)\n",
    "\n",
    "    #Unimos los dos anteriores variables en un solo dataset de entrenamiento del modelo\n",
    "    train = pd.concat([genuine_data, impostor_data])\n",
    "\n",
    "    #Obtenemos el X_train\n",
    "    X_train = train.loc[:, \"ft_1\":\"ft_60\" ]\n",
    "\n",
    "    #Obtenemos el y_train\n",
    "    y_train = train.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Generamos una copia temporal del dataset de desarrollo\n",
    "    temp2 = dev_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp2[\"user_id\"] = temp2[\"user_id\"].mask(temp2[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #df.sample(frac=0.5, replace=True, random_state=1)\n",
    "    X_dev = temp2.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_dev = temp2.loc[:, \"user_id\"]\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "\n",
    "    #Generamos una copia temporal del dataset de test\n",
    "    temp3 = test_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp3[\"user_id\"] = temp3[\"user_id\"].mask(temp3[\"user_id\"] != subject, 0)\n",
    "\n",
    "    X_test = temp3.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_test = temp3.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Entrenamos el modelo SVM\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state = 43, max_depth= 20, \n",
    "                                 max_features= 'auto',  min_samples_leaf= 1,\n",
    "                                   min_samples_split= 3, n_estimators= 700)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #clf = RandomForestClassifier(random_state = 43)\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Obtenemos probabilidades de cada registro del dataset de test\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    y_prob = pd.DataFrame(y_prob, columns = [\"probImpos\", \"probLegi\"])\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    #Para cada registro del subdataset de test\n",
    "    for index, row in test_users.iterrows():\n",
    "\n",
    "        temp_obj = {}\n",
    "\n",
    "        #user id del registro actual del subdataset de test\n",
    "        current_user_id = row[0]\n",
    "\n",
    "        #Vector de tiempo del registro actual del subdataset de test\n",
    "        current_data = row[1:]\n",
    "\n",
    "        #Actual modelo del usuario a evaluar\n",
    "        temp_obj[\"user_model\"] = subject\n",
    "\n",
    "        #user id del registro actual\n",
    "        temp_obj[\"user_id\"] = current_user_id\n",
    "\n",
    "        #Puntaje o score del modelo\n",
    "        temp_obj[\"score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Normalizacion del score\n",
    "        temp_obj[\"std_score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Variable que indica si el registro deberia de ser clasificado como genuino o impostor\n",
    "        if current_user_id == subject:\n",
    "            temp_obj[\"y_test\"] = \"genuine\"\n",
    "        else:\n",
    "            temp_obj[\"y_test\"] = \"impostor\"\n",
    "\n",
    "        users_evaluation_test.append(temp_obj)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "users_evaluation_test = pd.DataFrame(users_evaluation_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntaje de los registros del subdataset de test usando todos los modelos\n",
    " - **user_model:** modelo del usuario empleado para sacar el score\n",
    " - **user_id:** usuario del registro evaluado\n",
    " - **score:** puntuación que le dió el modelo\n",
    " - **std_score:** puntuación normalizada\n",
    " - **y_test:** cuando el user_model y user_id coinciden, entonces se usó un registro de usuario considerado genuino; caso contrario, es de un impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932143</td>\n",
       "      <td>0.932143</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.757881</td>\n",
       "      <td>0.757881</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904571</td>\n",
       "      <td>0.904571</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108390</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.468690</td>\n",
       "      <td>0.468690</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108391</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.067619</td>\n",
       "      <td>0.067619</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108392</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.870714</td>\n",
       "      <td>0.870714</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108393</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108394</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.885357</td>\n",
       "      <td>0.885357</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108395 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_model  user_id     score  std_score    y_test    y_pred\n",
       "0                1      1.0  0.974643   0.974643   genuine   genuine\n",
       "1                1      1.0  0.932143   0.932143   genuine   genuine\n",
       "2                1      1.0  0.995714   0.995714   genuine   genuine\n",
       "3                1      1.0  0.757881   0.757881   genuine   genuine\n",
       "4                1      1.0  0.904571   0.904571   genuine   genuine\n",
       "...            ...      ...       ...        ...       ...       ...\n",
       "108390         133    132.0  0.468690   0.468690  impostor  impostor\n",
       "108391         133    132.0  0.067619   0.067619  impostor  impostor\n",
       "108392         133    133.0  0.870714   0.870714   genuine   genuine\n",
       "108393         133    133.0  0.878333   0.878333   genuine   genuine\n",
       "108394         133    133.0  0.885357   0.885357   genuine   genuine\n",
       "\n",
       "[108395 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OJO, aca se esta usando el score como umbral, si usaramos el score estandarizado, deberiamos de cambiar el sentido de la comparación\n",
    "users_evaluation_test['y_pred'] = np.where(users_evaluation_test['score'] >= thresh_dev, 'genuine', 'impostor')\n",
    "\n",
    "users_evaluation_test.to_excel(\"./output/outputPredRandomForestTest.xlsx\")\n",
    "\n",
    "#Presentamos el calculo de resultados\n",
    "users_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los y_test y y_pred de nuestros resultados\n",
    "y_test_test = users_evaluation_test.loc[:, \"y_test\"]\n",
    "y_pred_test = users_evaluation_test.loc[:, \"y_pred\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "### Precisión del umbral hallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9564832326214309"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como genuinos por los modelos\n",
    "genuine_scores_test = list(users_evaluation_test.loc[users_evaluation_test.y_test == \"genuine\", \"score\"])\n",
    "\n",
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como impostores por los modelos\n",
    "impostor_scores_test = list(users_evaluation_test.loc[users_evaluation_test.y_test == \"impostor\", \"score\"])\n",
    "\n",
    "thresh_x, thresh_y, _ = find_fpr_and_tpr_given_a_threshold(genuine_scores_test, impostor_scores_test, thresh_dev)\n",
    "\n",
    "thresh_std = round(thresh_dev.tolist(), 3)\n",
    "\n",
    "#Ploteamos la curva ROC\n",
    "plotCurveROC_Threshold( genuine_scores_test, impostor_scores_test, thresh_std, thresh_x, thresh_y, \"black\",  title = \"ROC del modelo SVM con el dataset de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Random Forest - Modelo Usuario 1\")\n",
    "\n",
    "sc1 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 1), \"std_score\"]\n",
    "sc2 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 2), \"std_score\"]\n",
    "sc3 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 3), \"std_score\"]\n",
    "sc4 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 4), \"std_score\"]\n",
    "\n",
    "y1 = np.zeros(len(sc1))\n",
    "y2 = np.zeros(len(sc2))\n",
    "y3 = np.zeros(len(sc3))\n",
    "y4 = np.zeros(len(sc4))\n",
    "\n",
    "plt.scatter(sc1, y1, label = \"Usuario 1\")\n",
    "plt.scatter(sc2, y2, label = \"Usuario 2\")\n",
    "plt.scatter(sc3, y3, label = \"Usuario 3\")\n",
    "plt.scatter(sc4, y4, label = \"Usuario 4\")\n",
    "\n",
    "plt.plot(0.54190476, 0, marker= \"|\", color = \"blacK\", markersize= 25)\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Random Forest - Modelo Usuario 2\")\n",
    "\n",
    "sc1 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 1), \"std_score\"]\n",
    "sc2 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 2), \"std_score\"]\n",
    "sc3 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 3), \"std_score\"]\n",
    "sc4 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 4), \"std_score\"]\n",
    "\n",
    "y1 = np.zeros(len(sc1))\n",
    "y2 = np.zeros(len(sc2))\n",
    "y3 = np.zeros(len(sc3))\n",
    "y4 = np.zeros(len(sc4))\n",
    "\n",
    "plt.scatter(sc2, y2, label = \"Usuario 2\")\n",
    "plt.scatter(sc1, y1, label = \"Usuario 1\")\n",
    "plt.scatter(sc3, y3, label = \"Usuario 3\")\n",
    "plt.scatter(sc4, y4, label = \"Usuario 4\")\n",
    "\n",
    "plt.plot(0.54190476, 0, marker= \"|\", color = \"blacK\", markersize= 25)\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.min()[\"score\"]\n",
    "\n",
    "'{0:.0f}'.format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.max()[\"score\"]\n",
    "\n",
    "'{0:.0f}'.format(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00000000'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.min()[\"std_score\"]\n",
    "\n",
    "'{0:.8f}'.format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.00000000'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.max()[\"std_score\"]\n",
    "\n",
    "'{0:.8f}'.format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['age_bmi'] = df.age * df.bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar excel\n",
    "#users_evaluation.to_excel(\"output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
