{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score\n",
    "from scipy.spatial import distance\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método de función para encontrar el valor más cercano en un array\n",
    "Parámetros\n",
    "----------\n",
    "array : array\n",
    "value : valor que se debe de encontrar más cercano\n",
    "\n",
    "Retorno\n",
    "-------\n",
    "Indice en el array y su valor respectivo en el array\n",
    "\"\"\"\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx, array[idx]\n",
    "\n",
    "def find_fpr_and_tpr_given_a_threshold(genuine_scores, impostor_scores, threshold):\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    fprs, tprs, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    idx, value = find_nearest(thresholds, threshold)\n",
    "    return fprs[idx], tprs[idx], value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del método para evaluar el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_Model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy )\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del método para el cálculo del AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método para el cálculo del Area Under the Curve\n",
    "Parámetros\n",
    "----------\n",
    "user_scores : array con los scores o distancias del usuario legítimo\n",
    "impostor_scores : array con los scores o distancias de usuarios ilegítimos\n",
    "\n",
    "Retorno\n",
    "-------\n",
    "AUC: area bajo la curva ROC\n",
    "\"\"\"\n",
    "def evaluate_AUC(genuine_scores, impostor_scores):\n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    auc_score = roc_auc_score(labels, genuine_scores + impostor_scores)\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método para el cálculo del ERR\n",
    "Parámetros\n",
    "----------\n",
    "user_scores : array con los scores o distancias del usuario legítimo\n",
    "impostor_scores : array con los scores o distancias de usuarios ilegítimos\n",
    "\n",
    "Retorno\n",
    "-------\n",
    "Equal Error Rate: punto donde los missrates y los far\n",
    "\"\"\"\n",
    "#Primera forma de hallar el ERR\n",
    "def evaluate_EER(genuine_scores, impostor_scores):\n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    #Variable con los False Negative Rate (FNR) - miss\n",
    "    missrates = 1 - tpr\n",
    "    \n",
    "    #Variable con los False Positive Rate (FPR) - false alarm\n",
    "    farates = fpr\n",
    "    \n",
    "    #Se hallan las distancias entre los FNR y FPR dado cierto umbral\n",
    "    dists = missrates - farates\n",
    "    \n",
    "    #Listas que separan las distancias con los valores \n",
    "    #que estan más cercano al cero tanto superior como inferior\n",
    "    tempList1 = dists[dists >= 0]\n",
    "    tempList2 = dists[dists < 0]\n",
    "    \n",
    "    #Se busca el punto en la curva ROC donde se interceptan geométricamente el FNR y FPR\n",
    "    #El primero que sea el cercano superior al false alarm (>=)\n",
    "    #y aquel que este pegado a este en la curva pero siendo el cercano inferior (<)\n",
    "    # argmin te arroja el indice el item con los menores valores\n",
    "    # argmax te arroja el indice el item con los mayores valores\n",
    "    #idx es una variable que almacena este índice\n",
    "    \n",
    "    #Indice del menor elemento del tempList1 (Lo más pegado al cero superiormente)\n",
    "    idx1 = np.argmin(tempList1)\n",
    "    #Sacar el indice del valor de idx1 (en tempList1), pero en la lista \"dists\"\n",
    "    idx1, = np.where(dists == tempList1[idx1])\n",
    "    \n",
    "    #Indice del mayor elemento del tempList2 (Lo más pegado al cero inferiormente)\n",
    "    idx2 = np.argmax(tempList2)\n",
    "    #Sacar el indice del valor de idx2 (en tempList2), pero en la lista \"dists\"\n",
    "    idx2, = np.where(dists == tempList2[idx2])\n",
    "    \n",
    "    #Se determina es valor de los dos puntos y ponerlo en la variable x e y\n",
    "    x = [missrates[idx1], farates[idx1]]\n",
    "    y = [missrates[idx2], farates[idx2]]\n",
    "\n",
    "    #encuentrar el punto en la línea entre x e y en donde \n",
    "    #los primeros y segundos elementos del vector sean iguales.\n",
    "    #Específicamente, la línea que pasa a través de x e y \n",
    "    #se define como x + a * (y-x) para todo \"a\"\n",
    "    #Si usamos esta formula y lo igualamos, ya q x e y \n",
    "    #deben de coincidir en ese punto de la recta\n",
    "    #  -> x[1] + a*(y[1]-x[1]) = x[2] + a*(y[2]-x[2])\n",
    "    #lo factorizamos para determinar a\n",
    "    #que seria la pendiente de la recta que construiremos\n",
    "    #  -> a = (x[1] - x[2]) / (y[2]-x[2]-y[1]+x[1]) \n",
    "    \n",
    "    a = ( x[0] - x[1] ) / ( y[1] - x[1] - y[0] + x[0] )\n",
    "    eer = x[0] + a * ( y[0] - x[0] )\n",
    "    \n",
    "    return eer\n",
    "\n",
    "\n",
    "#Segunda forma de hallar el EER.\n",
    "def evaluate_EER_Thresh(genuine_scores, impostor_scores):\n",
    "    \n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1]*len(genuine_scores) + [0]*len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    #Se calcula el EER cuando el punto del fpr y del fpr se encuentran\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    \n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    return eer, thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del método para graficar curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCurveROC(genuine_scores, impostor_scores, title = 'Receiver Operating Characteristic'):\n",
    "    \n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    roc_auc = evaluate_AUC(genuine_scores, impostor_scores)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "def plotCurveROC_Threshold(genuine_scores, impostor_scores, threshold_value , threshold_x, threshold_y , color = \"green\" , title = 'Receiver Operating Characteristic'):\n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    roc_auc = evaluate_AUC(genuine_scores, impostor_scores)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.scatter(threshold_x ,threshold_y, color = color)\n",
    "    plt.text(threshold_x + 0.025, threshold_y - 0.05 , threshold_value)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de archivo y eliminación de registros no válidos\n",
    "Se eliminan los registros que NO hayan escrito la palabra greyc laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Se define la ruta donde se encuentra el archivo y se establece la conexión\n",
    "path = \"./data/grey/keystroke.db\"\n",
    "conn = sqlite3.connect(path)\n",
    "\n",
    "#Se hace la lectura y se almacena los datos extraídos en la variable df (\"dataframe\")\n",
    "df = pd.read_sql_query('select * from keystroke_datas', conn, parse_dates=['date'])\n",
    "\n",
    "#Se eliminan los registros de los usuarios que no hallan escrito la palabra 'greyc laboratory'\n",
    "df.drop(df[df['password'] != 'greyc laboratory'].index, inplace = True)\n",
    "\n",
    "#Se hace un cierre de la conexión con la base de datos SQLite\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsualización del dataset original\n",
    " El siguiente dataset contiene las siguientes columnas:\n",
    "  - ppTime: vector de tiempo entre dos teclas presionadas (press - press)\n",
    "  - rrTime: vector de tiempo entre dos teclas soltadas (release - release)\n",
    "  - prTime: vector de tiempo entre una tecla presionada y luego soltada (press - release)\n",
    "  - rpTime: vector de tiempo entre una tecla soltada y luego presionada (release - press)\n",
    "  - vector: este vector concatena todos los vectores anteriores en uno solo\n",
    "  - password: palabra escrita  por el usuario\n",
    "  - user_id: id del usuario\n",
    "  - time_to_type: tiempo que tardo en escribir la palabra\n",
    "  - rawPress: data cruda extraida de las teclas presionadas\n",
    "  - rawRelease: data cruda extraida de las teclas soltadas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ppTime</th>\n",
       "      <th>rrTime</th>\n",
       "      <th>prTime</th>\n",
       "      <th>rpTime</th>\n",
       "      <th>vector</th>\n",
       "      <th>password</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time_to_type</th>\n",
       "      <th>rawPress</th>\n",
       "      <th>rawRelease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2203168 600864 1101584 1602304 801152 2303312...</td>\n",
       "      <td>2203168 901296 500720 2503600 600864 1902736 ...</td>\n",
       "      <td>3204608 1902736 1802592 3204608 2203168 33047...</td>\n",
       "      <td>1201728 -400576 -200288 901296 -801152 901296...</td>\n",
       "      <td>2203168 600864 1101584 1602304 801152 2303312...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:09</td>\n",
       "      <td>30644064</td>\n",
       "      <td>71 633729665463844160\\n82 633729665466047328\\n...</td>\n",
       "      <td>71 633729665464845600\\n82 633729665467048768\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2103024 500720 2703888 1602304 2103024 340489...</td>\n",
       "      <td>1902736 701008 2203168 1802592 2203168 310446...</td>\n",
       "      <td>3104464 1702448 3404896 2503600 3104464 41059...</td>\n",
       "      <td>901296 -500720 1502160 901296 1201728 2403456...</td>\n",
       "      <td>2103024 500720 2703888 1602304 2103024 340489...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:18</td>\n",
       "      <td>33748528</td>\n",
       "      <td>71 633729665547564544\\n82 633729665549667568\\n...</td>\n",
       "      <td>71 633729665548766272\\n82 633729665550669008\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2203168 701008 1402016 1301872 2303312 330475...</td>\n",
       "      <td>2503600 801152 901296 1602304 2203168 3104464...</td>\n",
       "      <td>3304752 1902736 2103024 2303312 3204608 40057...</td>\n",
       "      <td>1402016 -400576 200288 600864 1301872 2403456...</td>\n",
       "      <td>2203168 701008 1402016 1301872 2303312 330475...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:28</td>\n",
       "      <td>29442336</td>\n",
       "      <td>71 633729665651914592\\n82 633729665654117760\\n...</td>\n",
       "      <td>71 633729665652715744\\n82 633729665655219344\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2103024 701008 1902736 1702448 1602304 260374...</td>\n",
       "      <td>2303312 701008 1402016 2002880 1602304 240345...</td>\n",
       "      <td>3304752 1902736 2603744 2703888 2603744 34048...</td>\n",
       "      <td>1101584 -500720 701008 1001440 600864 1602304...</td>\n",
       "      <td>2103024 701008 1902736 1702448 1602304 260374...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:48</td>\n",
       "      <td>31545360</td>\n",
       "      <td>71 633729665853404320\\n82 633729665855507344\\n...</td>\n",
       "      <td>71 633729665854405760\\n82 633729665856709072\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2002880 600864 1201728 1602304 1502160 300432...</td>\n",
       "      <td>2002880 901296 701008 1802592 1502160 2703888...</td>\n",
       "      <td>2904176 1802592 1902736 2503600 2403456 36051...</td>\n",
       "      <td>1101584 -300432 0 901296 600864 2103024 50072...</td>\n",
       "      <td>2002880 600864 1201728 1602304 1502160 300432...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:58</td>\n",
       "      <td>29642624</td>\n",
       "      <td>71 633729665954750048\\n82 633729665956752928\\n...</td>\n",
       "      <td>71 633729665955651344\\n82 633729665957654224\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             ppTime  \\\n",
       "5   6   2203168 600864 1101584 1602304 801152 2303312...   \n",
       "6   7   2103024 500720 2703888 1602304 2103024 340489...   \n",
       "7   8   2203168 701008 1402016 1301872 2303312 330475...   \n",
       "8   9   2103024 701008 1902736 1702448 1602304 260374...   \n",
       "9  10   2002880 600864 1201728 1602304 1502160 300432...   \n",
       "\n",
       "                                              rrTime  \\\n",
       "5   2203168 901296 500720 2503600 600864 1902736 ...   \n",
       "6   1902736 701008 2203168 1802592 2203168 310446...   \n",
       "7   2503600 801152 901296 1602304 2203168 3104464...   \n",
       "8   2303312 701008 1402016 2002880 1602304 240345...   \n",
       "9   2002880 901296 701008 1802592 1502160 2703888...   \n",
       "\n",
       "                                              prTime  \\\n",
       "5   3204608 1902736 1802592 3204608 2203168 33047...   \n",
       "6   3104464 1702448 3404896 2503600 3104464 41059...   \n",
       "7   3304752 1902736 2103024 2303312 3204608 40057...   \n",
       "8   3304752 1902736 2603744 2703888 2603744 34048...   \n",
       "9   2904176 1802592 1902736 2503600 2403456 36051...   \n",
       "\n",
       "                                              rpTime  \\\n",
       "5   1201728 -400576 -200288 901296 -801152 901296...   \n",
       "6   901296 -500720 1502160 901296 1201728 2403456...   \n",
       "7   1402016 -400576 200288 600864 1301872 2403456...   \n",
       "8   1101584 -500720 701008 1001440 600864 1602304...   \n",
       "9   1101584 -300432 0 901296 600864 2103024 50072...   \n",
       "\n",
       "                                              vector          password  \\\n",
       "5   2203168 600864 1101584 1602304 801152 2303312...  greyc laboratory   \n",
       "6   2103024 500720 2703888 1602304 2103024 340489...  greyc laboratory   \n",
       "7   2203168 701008 1402016 1301872 2303312 330475...  greyc laboratory   \n",
       "8   2103024 701008 1902736 1702448 1602304 260374...  greyc laboratory   \n",
       "9   2002880 600864 1201728 1602304 1502160 300432...  greyc laboratory   \n",
       "\n",
       "   user_id                date  time_to_type  \\\n",
       "5        1 2009-03-18 08:49:09      30644064   \n",
       "6        1 2009-03-18 08:49:18      33748528   \n",
       "7        1 2009-03-18 08:49:28      29442336   \n",
       "8        1 2009-03-18 08:49:48      31545360   \n",
       "9        1 2009-03-18 08:49:58      29642624   \n",
       "\n",
       "                                            rawPress  \\\n",
       "5  71 633729665463844160\\n82 633729665466047328\\n...   \n",
       "6  71 633729665547564544\\n82 633729665549667568\\n...   \n",
       "7  71 633729665651914592\\n82 633729665654117760\\n...   \n",
       "8  71 633729665853404320\\n82 633729665855507344\\n...   \n",
       "9  71 633729665954750048\\n82 633729665956752928\\n...   \n",
       "\n",
       "                                          rawRelease  \n",
       "5  71 633729665464845600\\n82 633729665467048768\\n...  \n",
       "6  71 633729665548766272\\n82 633729665550669008\\n...  \n",
       "7  71 633729665652715744\\n82 633729665655219344\\n...  \n",
       "8  71 633729665854405760\\n82 633729665856709072\\n...  \n",
       "9  71 633729665955651344\\n82 633729665957654224\\n...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de vectores de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Variable temporal para almacenar los items de la columna vector\n",
    "#ya que no se puede trabajar directamente con ese formato\n",
    "tempData = []\n",
    "\n",
    "#Variable con la cantidad de registros totales de la bd\n",
    "n_data_rows = df.shape[0]\n",
    "\n",
    "#Variable que tendrá la lista de columnas del dataframe\n",
    "columns = [\"user_id\"]   \n",
    "\n",
    "#Como existen en total 60 features de tiempo por usuario, se generará \n",
    "#los nombres de las columnas siguiento el siguiente formato \n",
    "#=> 'ft_'   +  posición del feature en el vector\n",
    "for i in range(60):\n",
    "    columns.append(\"ft_\" + str(i+1))\n",
    "\n",
    "#Por cada registro que existe en la bd se aplica lo siguente\n",
    "for i in range(n_data_rows):\n",
    "    \n",
    "    #Se extrae el usuario de ese registro\n",
    "    user_id = [df.iloc[i][\"user_id\"]]\n",
    "    #Se extrae el tiempo de tecleo\n",
    "    time_to_type = [df.iloc[i][\"time_to_type\"]]\n",
    "    \n",
    "    #Se crea el vector de tiempo\n",
    "    vector = df.iloc[i][\"vector\"].split()      \n",
    " \n",
    "    #Se verifica que la integridad del vector este OK,\n",
    "    #es decir que tenga una longitud exacta de 60 items\n",
    "    if(len(vector) == 60 ):\n",
    "        #Se aprega el registro a la variable temporarl tempData si cumple con la condición de integridad\n",
    "        tempData.append(user_id  + list(map(int, vector)))\n",
    "\n",
    "#Se crea el dataframe y se asigna a la variable df\n",
    "df = pd.DataFrame(tempData, columns = columns)\n",
    "\n",
    "#Se liberan recursos de la variable\n",
    "tempData.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsualización de dataset procesado\n",
    "Por cada registro, se tienen las siguientes columnas\n",
    " - Los features entre el 1 y 12 corresponden al vector de tiempo ppTime\n",
    " - Los features entre el 13 y 25 corresponden al vector de tiempo rrTime\n",
    " - Los features entre el 26 y 37 corresponden al vector de tiempo prTime\n",
    " - Los features entre el 38 y 60 corresponden al vector de tiempo rpTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2203168</td>\n",
       "      <td>600864</td>\n",
       "      <td>1101584</td>\n",
       "      <td>1602304</td>\n",
       "      <td>801152</td>\n",
       "      <td>2303312</td>\n",
       "      <td>1001440</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1402016</td>\n",
       "      <td>...</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2002880</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2002880</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2904176</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2303312</td>\n",
       "      <td>2103024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2103024</td>\n",
       "      <td>500720</td>\n",
       "      <td>2703888</td>\n",
       "      <td>1602304</td>\n",
       "      <td>2103024</td>\n",
       "      <td>3404896</td>\n",
       "      <td>1402016</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1402016</td>\n",
       "      <td>...</td>\n",
       "      <td>4105904</td>\n",
       "      <td>2303312</td>\n",
       "      <td>3505040</td>\n",
       "      <td>2103024</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2603744</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2103024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2203168</td>\n",
       "      <td>701008</td>\n",
       "      <td>1402016</td>\n",
       "      <td>1301872</td>\n",
       "      <td>2303312</td>\n",
       "      <td>3304752</td>\n",
       "      <td>901296</td>\n",
       "      <td>3004320</td>\n",
       "      <td>1502160</td>\n",
       "      <td>...</td>\n",
       "      <td>4005760</td>\n",
       "      <td>1902736</td>\n",
       "      <td>3905616</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2303312</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2603744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2103024</td>\n",
       "      <td>701008</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1702448</td>\n",
       "      <td>1602304</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1502160</td>\n",
       "      <td>3004320</td>\n",
       "      <td>1502160</td>\n",
       "      <td>...</td>\n",
       "      <td>3404896</td>\n",
       "      <td>2703888</td>\n",
       "      <td>4005760</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2303312</td>\n",
       "      <td>2403456</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2103024</td>\n",
       "      <td>2904176</td>\n",
       "      <td>2403456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2002880</td>\n",
       "      <td>600864</td>\n",
       "      <td>1201728</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1502160</td>\n",
       "      <td>3004320</td>\n",
       "      <td>1101584</td>\n",
       "      <td>2904176</td>\n",
       "      <td>1602304</td>\n",
       "      <td>...</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2203168</td>\n",
       "      <td>3905616</td>\n",
       "      <td>2303312</td>\n",
       "      <td>2603744</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2503600</td>\n",
       "      <td>2203168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     ft_1    ft_2     ft_3     ft_4     ft_5     ft_6     ft_7  \\\n",
       "0        1  2203168  600864  1101584  1602304   801152  2303312  1001440   \n",
       "1        1  2103024  500720  2703888  1602304  2103024  3404896  1402016   \n",
       "2        1  2203168  701008  1402016  1301872  2303312  3304752   901296   \n",
       "3        1  2103024  701008  1902736  1702448  1602304  2603744  1502160   \n",
       "4        1  2002880  600864  1201728  1602304  1502160  3004320  1101584   \n",
       "\n",
       "      ft_8     ft_9  ...    ft_51    ft_52    ft_53    ft_54    ft_55  \\\n",
       "0  2603744  1402016  ...  3304752  2002880  3605184  2002880  2804032   \n",
       "1  2603744  1402016  ...  4105904  2303312  3505040  2103024  2203168   \n",
       "2  3004320  1502160  ...  4005760  1902736  3905616  2203168  2303312   \n",
       "3  3004320  1502160  ...  3404896  2703888  4005760  2203168  2303312   \n",
       "4  2904176  1602304  ...  3605184  2203168  3905616  2303312  2603744   \n",
       "\n",
       "     ft_56    ft_57    ft_58    ft_59    ft_60  \n",
       "0  2403456  2904176  2403456  2303312  2103024  \n",
       "1  2603744  2804032  2603744  3104464  2103024  \n",
       "2  3104464  2603744  2203168  2203168  2603744  \n",
       "3  2403456  3104464  2103024  2904176  2403456  \n",
       "4  3104464  2603744  1902736  2503600  2203168  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación de la data de entrenamiento y de prueba\n",
    "Se toma de forma aleatoria el 80% de los registros de cada usuario para considerarlos como data de entrenamiento, el 10%  para la data de desarrollo del umbral y el 10 % restante para la data de prueba\n",
    "\n",
    "\n",
    "La función train_test_split cuando existe un grupo impar, siempre el último subgrupo recibe el elemento extra.\n",
    "Se trató de redondear el 0.80 del parámetro **train_size** debido a que cuando se trabaja con esta cantidad, arrojaba una mayor cantidad de splits con subdatasets de dev y de test desiguales. Aproximandamente **73**\n",
    "![Resultados usando una proporcion de 80](./img/Proportion%20split%2080.png)\n",
    "\n",
    "Poner 0.84 en el parámetro **train_size** permite tener menores grupos de subdatasets de dev y de test desiguales. En este solo se obtienen **4** de este tipo.\n",
    "> Se debe de mantener que el dataset de dev sea lo más similar al de test.\n",
    "\n",
    "[Link de fuente](https://cs230.stanford.edu/blog/split/)\n",
    "\n",
    "![Resultados usando una proporcion de 84](./img/Proportion%20split%2084.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable que contiene la lista de todos los usuarios de la bd\n",
    "subjects = df[\"user_id\"].unique()\n",
    "\n",
    "#Variable del dataset de train 80%\n",
    "train_users = []\n",
    "\n",
    "#Variable del dataset de dev (desarrollo) para el calculo del umbral 10%\n",
    "dev_users = []\n",
    "\n",
    "#Variable del dataset de test 10%\n",
    "test_users = []\n",
    "\n",
    "#Separar el df en 80 / 10 / 20 respectivamente y asignarlo a sus \n",
    "for subject in subjects:\n",
    "    current_user_data = df.loc[df.user_id == subject, :]\n",
    "            \n",
    "    #impostor_data = df.loc[df.user_id != subject, :]\n",
    "    \n",
    "    #Caso especial de una proporcion de 60/20/20 cuando el usuario tiene solo 5 registros\n",
    "    #Para no eliminar ese registro y no lanze error \n",
    "    #Donde quedaría asi 5 -> 3 / 1 / 1\n",
    "\n",
    "    if len(current_user_data) == 5:\n",
    "        train, dev = train_test_split(current_user_data, train_size = 0.6, random_state=43, shuffle=True)\n",
    "        dev , test = train_test_split(dev, train_size = 0.5, random_state=43, shuffle=True)\n",
    "    \n",
    "    #Caso contrario se respeta la proporcion de 80/10/10 establecida antes\n",
    "    else:\n",
    "        train, dev = train_test_split(current_user_data, train_size = 0.80, random_state=43, shuffle=True)\n",
    "        dev , test = train_test_split(dev, train_size = 0.5, random_state=43, shuffle=True)\n",
    "        \n",
    "    #Se agregan a los 3 datasets los splits calculados aleatoriamente\n",
    "    train_users.append(train)\n",
    "    dev_users.append(dev)\n",
    "    test_users.append(test)\n",
    "\n",
    "#Se convierte los arrays en dataframes manipulables\n",
    "train_users = pd.concat(train_users)\n",
    "dev_users = pd.concat(dev_users)\n",
    "test_users = pd.concat(test_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsualización del dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>1</td>\n",
       "      <td>2103024</td>\n",
       "      <td>701008</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1001440</td>\n",
       "      <td>1001440</td>\n",
       "      <td>2002880</td>\n",
       "      <td>500720</td>\n",
       "      <td>2403456</td>\n",
       "      <td>1402016</td>\n",
       "      <td>...</td>\n",
       "      <td>3004320</td>\n",
       "      <td>1702448</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2703888</td>\n",
       "      <td>1602304</td>\n",
       "      <td>2203168</td>\n",
       "      <td>1702448</td>\n",
       "      <td>3404896</td>\n",
       "      <td>1602304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2403456</td>\n",
       "      <td>600864</td>\n",
       "      <td>1402016</td>\n",
       "      <td>1602304</td>\n",
       "      <td>801152</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1201728</td>\n",
       "      <td>3004320</td>\n",
       "      <td>1702448</td>\n",
       "      <td>...</td>\n",
       "      <td>3204608</td>\n",
       "      <td>2303312</td>\n",
       "      <td>4306192</td>\n",
       "      <td>2503600</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2703888</td>\n",
       "      <td>2703888</td>\n",
       "      <td>2103024</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2203168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>1</td>\n",
       "      <td>1902736</td>\n",
       "      <td>701008</td>\n",
       "      <td>1001440</td>\n",
       "      <td>801152</td>\n",
       "      <td>1001440</td>\n",
       "      <td>1902736</td>\n",
       "      <td>500720</td>\n",
       "      <td>2603744</td>\n",
       "      <td>901296</td>\n",
       "      <td>...</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1702448</td>\n",
       "      <td>3404896</td>\n",
       "      <td>1602304</td>\n",
       "      <td>2904176</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1402016</td>\n",
       "      <td>2503600</td>\n",
       "      <td>1602304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>1</td>\n",
       "      <td>2002880</td>\n",
       "      <td>701008</td>\n",
       "      <td>1001440</td>\n",
       "      <td>1301872</td>\n",
       "      <td>1001440</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1702448</td>\n",
       "      <td>1602304</td>\n",
       "      <td>2904176</td>\n",
       "      <td>...</td>\n",
       "      <td>2904176</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2403456</td>\n",
       "      <td>4005760</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1802592</td>\n",
       "      <td>2703888</td>\n",
       "      <td>1902736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>1</td>\n",
       "      <td>2103024</td>\n",
       "      <td>701008</td>\n",
       "      <td>901296</td>\n",
       "      <td>1201728</td>\n",
       "      <td>701008</td>\n",
       "      <td>2403456</td>\n",
       "      <td>1001440</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1402016</td>\n",
       "      <td>...</td>\n",
       "      <td>3404896</td>\n",
       "      <td>1902736</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2103024</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2703888</td>\n",
       "      <td>2503600</td>\n",
       "      <td>1602304</td>\n",
       "      <td>3004320</td>\n",
       "      <td>1702448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7483</th>\n",
       "      <td>133</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2303312</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1702448</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2403456</td>\n",
       "      <td>...</td>\n",
       "      <td>3404896</td>\n",
       "      <td>3004320</td>\n",
       "      <td>3104464</td>\n",
       "      <td>3304752</td>\n",
       "      <td>6409216</td>\n",
       "      <td>3104464</td>\n",
       "      <td>3304752</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2403456</td>\n",
       "      <td>3705328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>133</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2002880</td>\n",
       "      <td>2103024</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1702448</td>\n",
       "      <td>3905616</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2303312</td>\n",
       "      <td>2203168</td>\n",
       "      <td>...</td>\n",
       "      <td>4706768</td>\n",
       "      <td>2804032</td>\n",
       "      <td>3304752</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2804032</td>\n",
       "      <td>3204608</td>\n",
       "      <td>7711088</td>\n",
       "      <td>3404896</td>\n",
       "      <td>2503600</td>\n",
       "      <td>3905616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>133</td>\n",
       "      <td>2203168</td>\n",
       "      <td>1802592</td>\n",
       "      <td>2203168</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1402016</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1602304</td>\n",
       "      <td>...</td>\n",
       "      <td>3805472</td>\n",
       "      <td>3204608</td>\n",
       "      <td>3004320</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2904176</td>\n",
       "      <td>2804032</td>\n",
       "      <td>5207488</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2603744</td>\n",
       "      <td>3505040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>133</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2002880</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2002880</td>\n",
       "      <td>1902736</td>\n",
       "      <td>5608064</td>\n",
       "      <td>1802592</td>\n",
       "      <td>1201728</td>\n",
       "      <td>1902736</td>\n",
       "      <td>...</td>\n",
       "      <td>6409216</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2002880</td>\n",
       "      <td>3104464</td>\n",
       "      <td>3304752</td>\n",
       "      <td>3605184</td>\n",
       "      <td>5107344</td>\n",
       "      <td>2603744</td>\n",
       "      <td>3004320</td>\n",
       "      <td>3805472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7312</th>\n",
       "      <td>133</td>\n",
       "      <td>2002880</td>\n",
       "      <td>2103024</td>\n",
       "      <td>3004320</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1502160</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1802592</td>\n",
       "      <td>2103024</td>\n",
       "      <td>...</td>\n",
       "      <td>3004320</td>\n",
       "      <td>2703888</td>\n",
       "      <td>2703888</td>\n",
       "      <td>3404896</td>\n",
       "      <td>4406336</td>\n",
       "      <td>3605184</td>\n",
       "      <td>4105904</td>\n",
       "      <td>2603744</td>\n",
       "      <td>3104464</td>\n",
       "      <td>5507920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5991 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id     ft_1     ft_2     ft_3     ft_4     ft_5     ft_6     ft_7  \\\n",
       "4797        1  2103024   701008  2603744  1001440  1001440  2002880   500720   \n",
       "12          1  2403456   600864  1402016  1602304   801152  2103024  1201728   \n",
       "3959        1  1902736   701008  1001440   801152  1001440  1902736   500720   \n",
       "6799        1  2002880   701008  1001440  1301872  1001440  2103024  1702448   \n",
       "2222        1  2103024   701008   901296  1201728   701008  2403456  1001440   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "7483      133  3304752  2403456  2303312  1902736  1702448  2203168  2103024   \n",
       "7480      133  1902736  2002880  2103024  2103024  1702448  3905616  1902736   \n",
       "7481      133  2203168  1802592  2203168  1602304  1402016  2603744  2203168   \n",
       "7308      133  1902736  2002880  1902736  2002880  1902736  5608064  1802592   \n",
       "7312      133  2002880  2103024  3004320  2603744  1502160  1902736  1602304   \n",
       "\n",
       "         ft_8     ft_9  ...    ft_51    ft_52    ft_53    ft_54    ft_55  \\\n",
       "4797  2403456  1402016  ...  3004320  1702448  3605184  2203168  2703888   \n",
       "12    3004320  1702448  ...  3204608  2303312  4306192  2503600  2603744   \n",
       "3959  2603744   901296  ...  2603744  1702448  3404896  1602304  2904176   \n",
       "6799  1602304  2904176  ...  2904176  2804032  2403456  4005760  3304752   \n",
       "2222  2103024  1402016  ...  3404896  1902736  3304752  2103024  3104464   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "7483  1902736  2403456  ...  3404896  3004320  3104464  3304752  6409216   \n",
       "7480  2303312  2203168  ...  4706768  2804032  3304752  3104464  2804032   \n",
       "7481  2103024  1602304  ...  3805472  3204608  3004320  2804032  2904176   \n",
       "7308  1201728  1902736  ...  6409216  2603744  2002880  3104464  3304752   \n",
       "7312  1802592  2103024  ...  3004320  2703888  2703888  3404896  4406336   \n",
       "\n",
       "        ft_56    ft_57    ft_58    ft_59    ft_60  \n",
       "4797  1602304  2203168  1702448  3404896  1602304  \n",
       "12    2703888  2703888  2103024  2603744  2203168  \n",
       "3959  2403456  2103024  1402016  2503600  1602304  \n",
       "6799  2603744  2603744  1802592  2703888  1902736  \n",
       "2222  2703888  2503600  1602304  3004320  1702448  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "7483  3104464  3304752  1902736  2403456  3705328  \n",
       "7480  3204608  7711088  3404896  2503600  3905616  \n",
       "7481  2804032  5207488  2603744  2603744  3505040  \n",
       "7308  3605184  5107344  2603744  3004320  3805472  \n",
       "7312  3605184  4105904  2603744  3104464  5507920  \n",
       "\n",
       "[5991 rows x 61 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsualización del dataset de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2203168</td>\n",
       "      <td>400576</td>\n",
       "      <td>2703888</td>\n",
       "      <td>1802592</td>\n",
       "      <td>1702448</td>\n",
       "      <td>2904176</td>\n",
       "      <td>1301872</td>\n",
       "      <td>3104464</td>\n",
       "      <td>1201728</td>\n",
       "      <td>...</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2303312</td>\n",
       "      <td>4105904</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2503600</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2703888</td>\n",
       "      <td>2103024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>1</td>\n",
       "      <td>1902736</td>\n",
       "      <td>701008</td>\n",
       "      <td>1502160</td>\n",
       "      <td>1101584</td>\n",
       "      <td>701008</td>\n",
       "      <td>2403456</td>\n",
       "      <td>1001440</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1201728</td>\n",
       "      <td>...</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2203168</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2103024</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2503600</td>\n",
       "      <td>2403456</td>\n",
       "      <td>1702448</td>\n",
       "      <td>3004320</td>\n",
       "      <td>2303312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>1</td>\n",
       "      <td>2203168</td>\n",
       "      <td>701008</td>\n",
       "      <td>1301872</td>\n",
       "      <td>1101584</td>\n",
       "      <td>801152</td>\n",
       "      <td>2303312</td>\n",
       "      <td>500720</td>\n",
       "      <td>2503600</td>\n",
       "      <td>1502160</td>\n",
       "      <td>...</td>\n",
       "      <td>3304752</td>\n",
       "      <td>1802592</td>\n",
       "      <td>3705328</td>\n",
       "      <td>2303312</td>\n",
       "      <td>3004320</td>\n",
       "      <td>2904176</td>\n",
       "      <td>2703888</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2703888</td>\n",
       "      <td>2503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2103024</td>\n",
       "      <td>600864</td>\n",
       "      <td>1201728</td>\n",
       "      <td>1702448</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2403456</td>\n",
       "      <td>1402016</td>\n",
       "      <td>3505040</td>\n",
       "      <td>1502160</td>\n",
       "      <td>...</td>\n",
       "      <td>3204608</td>\n",
       "      <td>2503600</td>\n",
       "      <td>4406336</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2503600</td>\n",
       "      <td>2703888</td>\n",
       "      <td>1802592</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2203168</td>\n",
       "      <td>600864</td>\n",
       "      <td>1101584</td>\n",
       "      <td>1602304</td>\n",
       "      <td>801152</td>\n",
       "      <td>2303312</td>\n",
       "      <td>1001440</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1402016</td>\n",
       "      <td>...</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2002880</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2002880</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2904176</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2303312</td>\n",
       "      <td>2103024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>132</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1502160</td>\n",
       "      <td>1802592</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1602304</td>\n",
       "      <td>2904176</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1402016</td>\n",
       "      <td>1902736</td>\n",
       "      <td>...</td>\n",
       "      <td>3705328</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2603744</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2303312</td>\n",
       "      <td>1201728</td>\n",
       "      <td>3805472</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2904176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7359</th>\n",
       "      <td>132</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1201728</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1702448</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1402016</td>\n",
       "      <td>1802592</td>\n",
       "      <td>1402016</td>\n",
       "      <td>...</td>\n",
       "      <td>3404896</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2203168</td>\n",
       "      <td>3404896</td>\n",
       "      <td>2403456</td>\n",
       "      <td>1402016</td>\n",
       "      <td>5507920</td>\n",
       "      <td>3605184</td>\n",
       "      <td>10314832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7140</th>\n",
       "      <td>132</td>\n",
       "      <td>2303312</td>\n",
       "      <td>1502160</td>\n",
       "      <td>2203168</td>\n",
       "      <td>1802592</td>\n",
       "      <td>2002880</td>\n",
       "      <td>3805472</td>\n",
       "      <td>1402016</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1702448</td>\n",
       "      <td>...</td>\n",
       "      <td>4506480</td>\n",
       "      <td>2503600</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2503600</td>\n",
       "      <td>3705328</td>\n",
       "      <td>2703888</td>\n",
       "      <td>1902736</td>\n",
       "      <td>6909936</td>\n",
       "      <td>3004320</td>\n",
       "      <td>4105904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7314</th>\n",
       "      <td>133</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2103024</td>\n",
       "      <td>5608064</td>\n",
       "      <td>2804032</td>\n",
       "      <td>1301872</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1402016</td>\n",
       "      <td>1702448</td>\n",
       "      <td>2103024</td>\n",
       "      <td>...</td>\n",
       "      <td>3004320</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2804032</td>\n",
       "      <td>3304752</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2904176</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2303312</td>\n",
       "      <td>3605184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>133</td>\n",
       "      <td>1702448</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1402016</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2303312</td>\n",
       "      <td>1402016</td>\n",
       "      <td>2203168</td>\n",
       "      <td>...</td>\n",
       "      <td>3104464</td>\n",
       "      <td>3505040</td>\n",
       "      <td>2603744</td>\n",
       "      <td>3404896</td>\n",
       "      <td>2804032</td>\n",
       "      <td>3004320</td>\n",
       "      <td>6008640</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2904176</td>\n",
       "      <td>9513680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id     ft_1     ft_2     ft_3     ft_4     ft_5     ft_6     ft_7  \\\n",
       "11          1  2203168   400576  2703888  1802592  1702448  2904176  1301872   \n",
       "4789        1  1902736   701008  1502160  1101584   701008  2403456  1001440   \n",
       "2323        1  2203168   701008  1301872  1101584   801152  2303312   500720   \n",
       "8           1  2103024   600864  1201728  1702448  3104464  2403456  1402016   \n",
       "0           1  2203168   600864  1101584  1602304   801152  2303312  1001440   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "7148      132  2103024  1502160  1802592  1602304  1602304  2904176  1602304   \n",
       "7359      132  2103024  1201728  1602304  1602304  1702448  2603744  1402016   \n",
       "7140      132  2303312  1502160  2203168  1802592  2002880  3805472  1402016   \n",
       "7314      133  1902736  2103024  5608064  2804032  1301872  1902736  1402016   \n",
       "7487      133  1702448  1902736  1902736  2103024  1402016  2203168  2303312   \n",
       "\n",
       "         ft_8     ft_9  ...    ft_51    ft_52    ft_53    ft_54    ft_55  \\\n",
       "11    3104464  1201728  ...  3605184  2303312  4105904  2203168  2403456   \n",
       "4789  2103024  1201728  ...  3605184  2203168  3304752  2103024  3304752   \n",
       "2323  2503600  1502160  ...  3304752  1802592  3705328  2303312  3004320   \n",
       "8     3505040  1502160  ...  3204608  2503600  4406336  2203168  2403456   \n",
       "0     2603744  1402016  ...  3304752  2002880  3605184  2002880  2804032   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "7148  1402016  1902736  ...  3705328  2603744  2203168  2603744  3304752   \n",
       "7359  1802592  1402016  ...  3404896  2403456  2403456  2203168  3404896   \n",
       "7140  1902736  1702448  ...  4506480  2503600  2804032  2503600  3705328   \n",
       "7314  1702448  2103024  ...  3004320  2603744  2804032  3304752  3104464   \n",
       "7487  1402016  2203168  ...  3104464  3505040  2603744  3404896  2804032   \n",
       "\n",
       "        ft_56    ft_57    ft_58    ft_59     ft_60  \n",
       "11    2503600  2603744  2203168  2703888   2103024  \n",
       "4789  2503600  2403456  1702448  3004320   2303312  \n",
       "2323  2904176  2703888  2203168  2703888   2503600  \n",
       "8     2503600  2703888  1802592  2603744   2503600  \n",
       "0     2403456  2904176  2403456  2303312   2103024  \n",
       "...       ...      ...      ...      ...       ...  \n",
       "7148  2303312  1201728  3805472  3605184   2904176  \n",
       "7359  2403456  1402016  5507920  3605184  10314832  \n",
       "7140  2703888  1902736  6909936  3004320   4105904  \n",
       "7314  2904176  3605184  2403456  2303312   3605184  \n",
       "7487  3004320  6008640  2203168  2904176   9513680  \n",
       "\n",
       "[742 rows x 61 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsualización del dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6795</th>\n",
       "      <td>1</td>\n",
       "      <td>2503600</td>\n",
       "      <td>400576</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1201728</td>\n",
       "      <td>701008</td>\n",
       "      <td>2203168</td>\n",
       "      <td>1301872</td>\n",
       "      <td>2303312</td>\n",
       "      <td>2804032</td>\n",
       "      <td>...</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2603744</td>\n",
       "      <td>3404896</td>\n",
       "      <td>3705328</td>\n",
       "      <td>3204608</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2904176</td>\n",
       "      <td>1902736</td>\n",
       "      <td>3204608</td>\n",
       "      <td>2303312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>1</td>\n",
       "      <td>1702448</td>\n",
       "      <td>701008</td>\n",
       "      <td>1101584</td>\n",
       "      <td>901296</td>\n",
       "      <td>701008</td>\n",
       "      <td>2002880</td>\n",
       "      <td>500720</td>\n",
       "      <td>2303312</td>\n",
       "      <td>901296</td>\n",
       "      <td>...</td>\n",
       "      <td>2804032</td>\n",
       "      <td>1602304</td>\n",
       "      <td>3404896</td>\n",
       "      <td>1702448</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2203168</td>\n",
       "      <td>1602304</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1502160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>1</td>\n",
       "      <td>1902736</td>\n",
       "      <td>701008</td>\n",
       "      <td>1502160</td>\n",
       "      <td>1101584</td>\n",
       "      <td>901296</td>\n",
       "      <td>2203168</td>\n",
       "      <td>1201728</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2603744</td>\n",
       "      <td>...</td>\n",
       "      <td>3204608</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2904176</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2904176</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2303312</td>\n",
       "      <td>1101584</td>\n",
       "      <td>2804032</td>\n",
       "      <td>1602304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1</td>\n",
       "      <td>1602304</td>\n",
       "      <td>901296</td>\n",
       "      <td>901296</td>\n",
       "      <td>1702448</td>\n",
       "      <td>901296</td>\n",
       "      <td>1802592</td>\n",
       "      <td>1201728</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1402016</td>\n",
       "      <td>...</td>\n",
       "      <td>3004320</td>\n",
       "      <td>2303312</td>\n",
       "      <td>4206048</td>\n",
       "      <td>2403456</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2503600</td>\n",
       "      <td>2403456</td>\n",
       "      <td>2503600</td>\n",
       "      <td>2303312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>1</td>\n",
       "      <td>2503600</td>\n",
       "      <td>801152</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1201728</td>\n",
       "      <td>1001440</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1201728</td>\n",
       "      <td>2403456</td>\n",
       "      <td>1802592</td>\n",
       "      <td>...</td>\n",
       "      <td>3004320</td>\n",
       "      <td>2403456</td>\n",
       "      <td>3805472</td>\n",
       "      <td>2503600</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2804032</td>\n",
       "      <td>1702448</td>\n",
       "      <td>3505040</td>\n",
       "      <td>1902736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>132</td>\n",
       "      <td>2002880</td>\n",
       "      <td>1402016</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1802592</td>\n",
       "      <td>1602304</td>\n",
       "      <td>2804032</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1502160</td>\n",
       "      <td>2103024</td>\n",
       "      <td>...</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2203168</td>\n",
       "      <td>2904176</td>\n",
       "      <td>3304752</td>\n",
       "      <td>2603744</td>\n",
       "      <td>1702448</td>\n",
       "      <td>5307632</td>\n",
       "      <td>3705328</td>\n",
       "      <td>3404896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>132</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1702448</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1402016</td>\n",
       "      <td>1702448</td>\n",
       "      <td>2804032</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1602304</td>\n",
       "      <td>2002880</td>\n",
       "      <td>...</td>\n",
       "      <td>3805472</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2603744</td>\n",
       "      <td>2904176</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2403456</td>\n",
       "      <td>1902736</td>\n",
       "      <td>4306192</td>\n",
       "      <td>3505040</td>\n",
       "      <td>2403456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>133</td>\n",
       "      <td>2103024</td>\n",
       "      <td>2904176</td>\n",
       "      <td>3505040</td>\n",
       "      <td>3805472</td>\n",
       "      <td>1201728</td>\n",
       "      <td>2103024</td>\n",
       "      <td>4806912</td>\n",
       "      <td>1402016</td>\n",
       "      <td>2603744</td>\n",
       "      <td>...</td>\n",
       "      <td>3304752</td>\n",
       "      <td>5808352</td>\n",
       "      <td>2603744</td>\n",
       "      <td>3805472</td>\n",
       "      <td>2403456</td>\n",
       "      <td>3505040</td>\n",
       "      <td>4206048</td>\n",
       "      <td>2904176</td>\n",
       "      <td>2804032</td>\n",
       "      <td>3905616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>133</td>\n",
       "      <td>2203168</td>\n",
       "      <td>1802592</td>\n",
       "      <td>1702448</td>\n",
       "      <td>1201728</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2103024</td>\n",
       "      <td>1402016</td>\n",
       "      <td>4005760</td>\n",
       "      <td>...</td>\n",
       "      <td>3304752</td>\n",
       "      <td>3004320</td>\n",
       "      <td>1902736</td>\n",
       "      <td>5007200</td>\n",
       "      <td>4306192</td>\n",
       "      <td>4005760</td>\n",
       "      <td>3805472</td>\n",
       "      <td>2703888</td>\n",
       "      <td>3204608</td>\n",
       "      <td>4105904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>133</td>\n",
       "      <td>1902736</td>\n",
       "      <td>1902736</td>\n",
       "      <td>2303312</td>\n",
       "      <td>1702448</td>\n",
       "      <td>1702448</td>\n",
       "      <td>2002880</td>\n",
       "      <td>1602304</td>\n",
       "      <td>1702448</td>\n",
       "      <td>3004320</td>\n",
       "      <td>...</td>\n",
       "      <td>3104464</td>\n",
       "      <td>2804032</td>\n",
       "      <td>2804032</td>\n",
       "      <td>4105904</td>\n",
       "      <td>3705328</td>\n",
       "      <td>4206048</td>\n",
       "      <td>3605184</td>\n",
       "      <td>2703888</td>\n",
       "      <td>3304752</td>\n",
       "      <td>4606624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id     ft_1     ft_2     ft_3     ft_4     ft_5     ft_6     ft_7  \\\n",
       "6795        1  2503600   400576  1902736  1201728   701008  2203168  1301872   \n",
       "3954        1  1702448   701008  1101584   901296   701008  2002880   500720   \n",
       "6802        1  1902736   701008  1502160  1101584   901296  2203168  1201728   \n",
       "405         1  1602304   901296   901296  1702448   901296  1802592  1201728   \n",
       "4791        1  2503600   801152  2103024  1201728  1001440  2103024  1201728   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "6751      132  2002880  1402016  1602304  1802592  1602304  2804032  1602304   \n",
       "6754      132  2103024  1702448  1902736  1402016  1702448  2804032  1902736   \n",
       "7477      133  2103024  2904176  3505040  3805472  1201728  2103024  4806912   \n",
       "7313      133  2203168  1802592  1702448  1201728  1902736  1902736  2103024   \n",
       "7318      133  1902736  1902736  2303312  1702448  1702448  2002880  1602304   \n",
       "\n",
       "         ft_8     ft_9  ...    ft_51    ft_52    ft_53    ft_54    ft_55  \\\n",
       "6795  2303312  2804032  ...  3104464  2603744  3404896  3705328  3204608   \n",
       "3954  2303312   901296  ...  2804032  1602304  3404896  1702448  2804032   \n",
       "6802  1902736  2603744  ...  3204608  2403456  2904176  3304752  2904176   \n",
       "405   2603744  1402016  ...  3004320  2303312  4206048  2403456  3104464   \n",
       "4791  2403456  1802592  ...  3004320  2403456  3805472  2503600  3104464   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "6751  1502160  2103024  ...  3605184  2804032  2203168  2904176  3304752   \n",
       "6754  1602304  2002880  ...  3805472  2804032  2603744  2904176  3605184   \n",
       "7477  1402016  2603744  ...  3304752  5808352  2603744  3805472  2403456   \n",
       "7313  1402016  4005760  ...  3304752  3004320  1902736  5007200  4306192   \n",
       "7318  1702448  3004320  ...  3104464  2804032  2804032  4105904  3705328   \n",
       "\n",
       "        ft_56    ft_57    ft_58    ft_59    ft_60  \n",
       "6795  2403456  2904176  1902736  3204608  2303312  \n",
       "3954  2203168  2203168  1602304  2603744  1502160  \n",
       "6802  2603744  2303312  1101584  2804032  1602304  \n",
       "405   2603744  2503600  2403456  2503600  2303312  \n",
       "4791  2804032  2804032  1702448  3505040  1902736  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "6751  2603744  1702448  5307632  3705328  3404896  \n",
       "6754  2403456  1902736  4306192  3505040  2403456  \n",
       "7477  3505040  4206048  2904176  2804032  3905616  \n",
       "7313  4005760  3805472  2703888  3204608  4105904  \n",
       "7318  4206048  3605184  2703888  3304752  4606624  \n",
       "\n",
       "[815 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de las probablidades con los registros de test\n",
    "\n",
    "![Calculo de distancias](./img/Calculo%20de%20distancias.png)\n",
    "\n",
    "### Ejemplo del usuario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de los datos a usar para el usuario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aca obtenemos el X_train, y_train del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos una copia temporal del dataset de entrenamiento\n",
    "temp1 = train_users.copy()\n",
    "\n",
    "#Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "temp1[\"user_id\"] = temp1[\"user_id\"].mask(temp1[\"user_id\"] != 1, 0)\n",
    "\n",
    "#Obtenemos los registros considerados genuinos del entrenamiento\n",
    "genuine_data = temp1.loc[temp1.user_id == 1, :]\n",
    "\n",
    "#Obtenemos los registros considerados impostores del entrenamiento.\n",
    "#Este debe de ser del mismo tamaño que de los registros genuinos\n",
    "impostor_data = temp1.loc[temp1.user_id != 1, :].sample(n= genuine_data.shape[0], random_state=43)\n",
    "\n",
    "#Lo unimos los dos anteriores en un solo dataset de entrenamiento del modelo del usuario 1\n",
    "train = pd.concat([genuine_data, impostor_data])\n",
    "\n",
    "#Obtenemos el X_train\n",
    "X_train = train.loc[:, \"ft_1\":\"ft_60\" ]\n",
    "\n",
    "#Obtenemos el y_train\n",
    "y_train = train.loc[:, \"user_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtenemos el X_dev , y_dev, X_test y y_test del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos una copia temporal del dataset de desarrollo\n",
    "temp2 = dev_users.copy()\n",
    "\n",
    "#Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "temp2[\"user_id\"] = temp2[\"user_id\"].mask(temp2[\"user_id\"] != 1, 0)\n",
    "\n",
    "#df.sample(frac=0.5, replace=True, random_state=1)\n",
    "X_dev = temp2.loc[:, \"ft_1\":\"ft_60\"]\n",
    "y_dev = temp2.loc[:, \"user_id\"]\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "#Generamos una copia temporal del dataset de test\n",
    "temp3 = test_users.copy()\n",
    "\n",
    "#Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "temp3[\"user_id\"] = temp3[\"user_id\"].mask(temp3[\"user_id\"] != 1, 0)\n",
    "\n",
    "X_test = temp3.loc[:, \"ft_1\":\"ft_60\"]\n",
    "y_test = temp3.loc[:, \"user_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos la busqueda de los mejores hiperparámetros\n",
    "\n",
    "Comenzamos con un Random Search Cross Validation para deliminar el universo de busqueda de los parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 43,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#Creamos un modelo Random Forest\n",
    "rf = RandomForestClassifier(random_state = 43)\n",
    "\n",
    "#Mostramos parametros por default\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 110}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 300 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=43, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "search = rf_random.fit(X_train,y_train)\n",
    "\n",
    "#Mejores mejores parametros\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con los parámetros por default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9730458221024259\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 43)\n",
    "base_model.fit(X_train,y_train)\n",
    "base_accuracy = evaluate_Model(base_model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con los parámetros encontrados por el Random Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9784366576819407\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate_Model(best_random, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos uso de grid search para tener mejores pámetros, al rededor de los parámetros encontrados en el random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   57.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 700}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [20 ,30,40, 50, 60, None],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'n_estimators': [500, 600, 700]\n",
    "}\n",
    "\n",
    "#Creamos un modelo Random Forest\n",
    "rf = RandomForestClassifier(random_state = 43)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con los parámetros encontrados por el Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9784366576819407\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate_Model(best_grid, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo con mejores hiperparametros  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=600,\n",
       "                       n_jobs=None, oob_score=False, random_state=43, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos el modelo Random Forest\n",
    "clf = RandomForestClassifier(random_state = 43, max_depth= 20, \n",
    "                             max_features= 'auto',  min_samples_leaf= 1,\n",
    "                               min_samples_split= 2, n_estimators= 600)\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos las predicciones\n",
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado con el subdataset de prueba del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977088948787062\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de las probabilidades de cada registro usando el modelo del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probImpos</th>\n",
       "      <th>probLegi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068333</td>\n",
       "      <td>0.931667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.996667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0.948333</td>\n",
       "      <td>0.051667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.028333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.038333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     probImpos  probLegi\n",
       "0     0.025000  0.975000\n",
       "1     0.068333  0.931667\n",
       "2     0.003333  0.996667\n",
       "3     0.246667  0.753333\n",
       "4     0.100000  0.900000\n",
       "..         ...       ...\n",
       "810   0.948333  0.051667\n",
       "811   0.940000  0.060000\n",
       "812   0.971667  0.028333\n",
       "813   0.961667  0.038333\n",
       "814   0.985000  0.015000\n",
       "\n",
       "[815 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Con la función predict_proba obtenemos las probabilidades para cada clase.\n",
    "#En el primero, obtenemos la probalidad de que sea un registro de un usuario impostor\n",
    "#En el otro, obtenemos la probalidad de que el registro pertenesca al usuario 1 (legitimo)\n",
    "y_prob = clf.predict_proba(X_test)\n",
    "y_prob = pd.DataFrame(y_prob, columns = [\"probImpos\", \"probLegi\"])\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable donde se almacenará toda la informacion calculada del usuario 1 \n",
    "user_1_evaluation_dev = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "#Para cada registro del subdataset de test\n",
    "for index, row in dev_users.iterrows():\n",
    "    \n",
    "    temp_obj = {}\n",
    "    \n",
    "    #user id del registro actual del subdataset de test\n",
    "    current_user_id = row[0]\n",
    "    \n",
    "    #Vector de tiempo del registro actual del subdataset de test\n",
    "    current_data = row[1:]\n",
    "    \n",
    "    #Actual modelo del usuario a evaluar\n",
    "    temp_obj[\"user_model\"] = 1\n",
    "\n",
    "    #user id del registro actual\n",
    "    temp_obj[\"user_id\"] = current_user_id\n",
    "    \n",
    "    #Puntaje o score del modelo\n",
    "    temp_obj[\"score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "    #Normalizacion del score\n",
    "    temp_obj[\"std_score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "    \n",
    "    #Variable que indica si el registro deberia de ser clasificado como geniono o impostor\n",
    "    if current_user_id == 1:\n",
    "        temp_obj[\"y_test\"] = \"genuine\"\n",
    "    else:\n",
    "        temp_obj[\"y_test\"] = \"impostor\"\n",
    "    \n",
    "    user_1_evaluation_dev.append(temp_obj)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "user_1_evaluation_dev = pd.DataFrame(user_1_evaluation_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntaje de los registros del subdataset de desarrollo usando el modelo del usuario 1\n",
    " - **user_model:** modelo del usuario empleado para sacar el score\n",
    " - **user_id:** usuario del registro evaluado\n",
    " - **score:** puntuación que le dió el modelo\n",
    " - **std_score:** puntuación normalizada\n",
    " - **y_test:** cuando el user_model y user_id **(1)** coinciden, entonces se usó un registro de usuario considerado genuino; caso contrario, es de un impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_model  user_id     score  std_score    y_test\n",
       "0             1        1  0.975000   0.975000   genuine\n",
       "1             1        1  0.931667   0.931667   genuine\n",
       "2             1        1  0.996667   0.996667   genuine\n",
       "3             1        1  0.753333   0.753333   genuine\n",
       "4             1        1  0.900000   0.900000   genuine\n",
       "..          ...      ...       ...        ...       ...\n",
       "737           1      132  0.001667   0.001667  impostor\n",
       "738           1      132  0.056667   0.056667  impostor\n",
       "739           1      132  0.023333   0.023333  impostor\n",
       "740           1      133  0.041667   0.041667  impostor\n",
       "741           1      133  0.115000   0.115000  impostor\n",
       "\n",
       "[742 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_1_evaluation_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo usando los modelos de todos los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_evaluation_dev = []\n",
    "\n",
    "#Se hace el cálculo para cada usuario\n",
    "for subject in subjects:\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    #Generamos una copia temporal del dataset de entrenamiento\n",
    "    temp1 = train_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al sujeto actual por 0\n",
    "    temp1[\"user_id\"] = temp1[\"user_id\"].mask(temp1[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #Obtenemos los registros considerados genuinos del entrenamiento\n",
    "    genuine_data = temp1.loc[temp1.user_id == subject, :]\n",
    "\n",
    "    #Obtenemos los registros considerados impostores del entrenamiento.\n",
    "    #Este debe de ser del mismo tamaño que de los registros genuinos\n",
    "    impostor_data = temp1.loc[temp1.user_id != subject, :].sample(n= genuine_data.shape[0], random_state=43)\n",
    "\n",
    "    #Unimos los dos anteriores variables en un solo dataset de entrenamiento del modelo\n",
    "    train = pd.concat([genuine_data, impostor_data])\n",
    "\n",
    "    #Obtenemos el X_train\n",
    "    X_train = train.loc[:, \"ft_1\":\"ft_60\" ]\n",
    "\n",
    "    #Obtenemos el y_train\n",
    "    y_train = train.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Generamos una copia temporal del dataset de desarrollo\n",
    "    temp2 = dev_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp2[\"user_id\"] = temp2[\"user_id\"].mask(temp2[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #df.sample(frac=0.5, replace=True, random_state=1)\n",
    "    X_dev = temp2.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_dev = temp2.loc[:, \"user_id\"]\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "\n",
    "    #Generamos una copia temporal del dataset de test\n",
    "    temp3 = test_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp3[\"user_id\"] = temp3[\"user_id\"].mask(temp3[\"user_id\"] != subject, 0)\n",
    "\n",
    "    X_test = temp3.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_test = temp3.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Entrenamos el modelo Random Forest\n",
    "    \n",
    "    \n",
    "    clf = RandomForestClassifier(random_state = 43, max_depth= 20, \n",
    "                                 max_features= 'auto',  min_samples_leaf= 1,\n",
    "                                   min_samples_split= 3, n_estimators= 700)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #clf = RandomForestClassifier(random_state = 43)\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Obtenemos probabilidades de cada registro del dataset de test\n",
    "    y_prob = clf.predict_proba(X_dev)\n",
    "    y_prob = pd.DataFrame(y_prob, columns = [\"probImpos\", \"probLegi\"])\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    #Para cada registro del subdataset de test\n",
    "    for index, row in dev_users.iterrows():\n",
    "\n",
    "        temp_obj = {}\n",
    "\n",
    "        #user id del registro actual del subdataset de test\n",
    "        current_user_id = row[0]\n",
    "\n",
    "        #Vector de tiempo del registro actual del subdataset de test\n",
    "        current_data = row[1:]\n",
    "\n",
    "        #Actual modelo del usuario a evaluar\n",
    "        temp_obj[\"user_model\"] = subject\n",
    "\n",
    "        #user id del registro actual\n",
    "        temp_obj[\"user_id\"] = current_user_id\n",
    "\n",
    "        #Puntaje o score del modelo\n",
    "        temp_obj[\"score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Normalizacion del score\n",
    "        temp_obj[\"std_score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Variable que indica si el registro deberia de ser clasificado como genuino o impostor\n",
    "        if current_user_id == subject:\n",
    "            temp_obj[\"y_test\"] = \"genuine\"\n",
    "        else:\n",
    "            temp_obj[\"y_test\"] = \"impostor\"\n",
    "\n",
    "        users_evaluation_dev.append(temp_obj)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "users_evaluation_dev = pd.DataFrame(users_evaluation_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntaje de los registros del subdataset de test usando todos los modelos\n",
    " - **user_model:** modelo del usuario empleado para sacar el score\n",
    " - **user_id:** usuario del registro evaluado\n",
    " - **score:** puntuación que le dió el modelo\n",
    " - **std_score:** puntuación normalizada\n",
    " - **y_test:** cuando el user_model y user_id coinciden, entonces se usó un registro de usuario considerado genuino; caso contrario, es de un impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564429</td>\n",
       "      <td>0.564429</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940119</td>\n",
       "      <td>0.940119</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828310</td>\n",
       "      <td>0.828310</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98681</th>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>0.040476</td>\n",
       "      <td>0.040476</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98682</th>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>0.429643</td>\n",
       "      <td>0.429643</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98683</th>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>0.566548</td>\n",
       "      <td>0.566548</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98684</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>0.808929</td>\n",
       "      <td>0.808929</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98685</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98686 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_model  user_id     score  std_score    y_test\n",
       "0               1        1  0.564429   0.564429   genuine\n",
       "1               1        1  0.940119   0.940119   genuine\n",
       "2               1        1  0.996429   0.996429   genuine\n",
       "3               1        1  0.828310   0.828310   genuine\n",
       "4               1        1  0.852381   0.852381   genuine\n",
       "...           ...      ...       ...        ...       ...\n",
       "98681         133      132  0.040476   0.040476  impostor\n",
       "98682         133      132  0.429643   0.429643  impostor\n",
       "98683         133      132  0.566548   0.566548  impostor\n",
       "98684         133      133  0.808929   0.808929   genuine\n",
       "98685         133      133  0.976190   0.976190   genuine\n",
       "\n",
       "[98686 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_evaluation_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como genuinos por los modelos\n",
    "genuine_scores_dev = list(users_evaluation_dev.loc[users_evaluation_dev.y_test == \"genuine\", \"score\"])\n",
    "\n",
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como impostores por los modelos\n",
    "impostor_scores_dev = list(users_evaluation_dev.loc[users_evaluation_dev.y_test == \"impostor\", \"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo del umbral de decisión con el subdataset de DESARROLLO\n",
    "\n",
    "Buscamos el punto en donde los falsos negativos y los falsos positivos son iguales en los modelos de manera global\n",
    "![Calculo de umbral](./img/Calculo%20del%20umbral.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculo del ERR y del umbral de decisión global\n",
    "err_dev, thresh_dev = evaluate_EER_Thresh(genuine_scores_dev, impostor_scores_dev)\n",
    "\n",
    "\n",
    "#Ploteamos la curva ROC de los umbrales\n",
    "plotCurveROC ( genuine_scores_dev, impostor_scores_dev, title = \"ROC del modelo Random Forest con el dataset de validación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umbral de decisión global hallado (en formato score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.54080952)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respectiva tasa de error que nos daria el umbral de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04447439353097311"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564429</td>\n",
       "      <td>0.564429</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940119</td>\n",
       "      <td>0.940119</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828310</td>\n",
       "      <td>0.828310</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98681</th>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>0.040476</td>\n",
       "      <td>0.040476</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98682</th>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>0.429643</td>\n",
       "      <td>0.429643</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98683</th>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>0.566548</td>\n",
       "      <td>0.566548</td>\n",
       "      <td>impostor</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98684</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>0.808929</td>\n",
       "      <td>0.808929</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98685</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98686 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_model  user_id     score  std_score    y_test    y_pred\n",
       "0               1        1  0.564429   0.564429   genuine   genuine\n",
       "1               1        1  0.940119   0.940119   genuine   genuine\n",
       "2               1        1  0.996429   0.996429   genuine   genuine\n",
       "3               1        1  0.828310   0.828310   genuine   genuine\n",
       "4               1        1  0.852381   0.852381   genuine   genuine\n",
       "...           ...      ...       ...        ...       ...       ...\n",
       "98681         133      132  0.040476   0.040476  impostor  impostor\n",
       "98682         133      132  0.429643   0.429643  impostor  impostor\n",
       "98683         133      132  0.566548   0.566548  impostor   genuine\n",
       "98684         133      133  0.808929   0.808929   genuine   genuine\n",
       "98685         133      133  0.976190   0.976190   genuine   genuine\n",
       "\n",
       "[98686 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_evaluation_dev['y_pred'] = np.where(users_evaluation_dev['score'] >= thresh_dev, 'genuine', 'impostor')\n",
    "\n",
    "users_evaluation_dev.to_excel(\"./output/outputPredRandomForestDev.xlsx\")\n",
    "\n",
    "#Presentamos el calculo de resultados\n",
    "users_evaluation_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los y_test y y_pred de nuestros resultados\n",
    "y_test_dev = users_evaluation_dev.loc[:, \"y_test\"]\n",
    "y_pred_dev = users_evaluation_dev.loc[:, \"y_pred\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión del umbral hallado con el subdataset de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555357396185883"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_dev, y_pred_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del umbral usando el subdataset de PRUEBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_evaluation_test = []\n",
    "\n",
    "#Se hace el cálculo para cada usuario\n",
    "for subject in subjects:\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    #Generamos una copia temporal del dataset de entrenamiento\n",
    "    temp1 = train_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al sujeto actual por 0\n",
    "    temp1[\"user_id\"] = temp1[\"user_id\"].mask(temp1[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #Obtenemos los registros considerados genuinos del entrenamiento\n",
    "    genuine_data = temp1.loc[temp1.user_id == subject, :]\n",
    "\n",
    "    #Obtenemos los registros considerados impostores del entrenamiento.\n",
    "    #Este debe de ser del mismo tamaño que de los registros genuinos\n",
    "    impostor_data = temp1.loc[temp1.user_id != subject, :].sample(n= genuine_data.shape[0], random_state=43)\n",
    "\n",
    "    #Unimos los dos anteriores variables en un solo dataset de entrenamiento del modelo\n",
    "    train = pd.concat([genuine_data, impostor_data])\n",
    "\n",
    "    #Obtenemos el X_train\n",
    "    X_train = train.loc[:, \"ft_1\":\"ft_60\" ]\n",
    "\n",
    "    #Obtenemos el y_train\n",
    "    y_train = train.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Generamos una copia temporal del dataset de desarrollo\n",
    "    temp2 = dev_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp2[\"user_id\"] = temp2[\"user_id\"].mask(temp2[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #df.sample(frac=0.5, replace=True, random_state=1)\n",
    "    X_dev = temp2.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_dev = temp2.loc[:, \"user_id\"]\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "\n",
    "    #Generamos una copia temporal del dataset de test\n",
    "    temp3 = test_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp3[\"user_id\"] = temp3[\"user_id\"].mask(temp3[\"user_id\"] != subject, 0)\n",
    "\n",
    "    X_test = temp3.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_test = temp3.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Entrenamos el modelo SVM\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state = 43, max_depth= 20, \n",
    "                                 max_features= 'auto',  min_samples_leaf= 1,\n",
    "                                   min_samples_split= 3, n_estimators= 700)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #clf = RandomForestClassifier(random_state = 43)\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Obtenemos probabilidades de cada registro del dataset de test\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    y_prob = pd.DataFrame(y_prob, columns = [\"probImpos\", \"probLegi\"])\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    #Para cada registro del subdataset de test\n",
    "    for index, row in test_users.iterrows():\n",
    "\n",
    "        temp_obj = {}\n",
    "\n",
    "        #user id del registro actual del subdataset de test\n",
    "        current_user_id = row[0]\n",
    "\n",
    "        #Vector de tiempo del registro actual del subdataset de test\n",
    "        current_data = row[1:]\n",
    "\n",
    "        #Actual modelo del usuario a evaluar\n",
    "        temp_obj[\"user_model\"] = subject\n",
    "\n",
    "        #user id del registro actual\n",
    "        temp_obj[\"user_id\"] = current_user_id\n",
    "\n",
    "        #Puntaje o score del modelo\n",
    "        temp_obj[\"score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Normalizacion del score\n",
    "        temp_obj[\"std_score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Variable que indica si el registro deberia de ser clasificado como genuino o impostor\n",
    "        if current_user_id == subject:\n",
    "            temp_obj[\"y_test\"] = \"genuine\"\n",
    "        else:\n",
    "            temp_obj[\"y_test\"] = \"impostor\"\n",
    "\n",
    "        users_evaluation_test.append(temp_obj)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "users_evaluation_test = pd.DataFrame(users_evaluation_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntaje de los registros del subdataset de test usando todos los modelos\n",
    " - **user_model:** modelo del usuario empleado para sacar el score\n",
    " - **user_id:** usuario del registro evaluado\n",
    " - **score:** puntuación que le dió el modelo\n",
    " - **std_score:** puntuación normalizada\n",
    " - **y_test:** cuando el user_model y user_id coinciden, entonces se usó un registro de usuario considerado genuino; caso contrario, es de un impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932143</td>\n",
       "      <td>0.932143</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757881</td>\n",
       "      <td>0.757881</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904571</td>\n",
       "      <td>0.904571</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108390</th>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>0.468690</td>\n",
       "      <td>0.468690</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108391</th>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>0.067619</td>\n",
       "      <td>0.067619</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108392</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>0.870714</td>\n",
       "      <td>0.870714</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108393</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108394</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>0.886786</td>\n",
       "      <td>0.886786</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108395 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_model  user_id     score  std_score    y_test    y_pred\n",
       "0                1        1  0.974643   0.974643   genuine   genuine\n",
       "1                1        1  0.932143   0.932143   genuine   genuine\n",
       "2                1        1  0.995714   0.995714   genuine   genuine\n",
       "3                1        1  0.757881   0.757881   genuine   genuine\n",
       "4                1        1  0.904571   0.904571   genuine   genuine\n",
       "...            ...      ...       ...        ...       ...       ...\n",
       "108390         133      132  0.468690   0.468690  impostor  impostor\n",
       "108391         133      132  0.067619   0.067619  impostor  impostor\n",
       "108392         133      133  0.870714   0.870714   genuine   genuine\n",
       "108393         133      133  0.878333   0.878333   genuine   genuine\n",
       "108394         133      133  0.886786   0.886786   genuine   genuine\n",
       "\n",
       "[108395 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OJO, aca se esta usando el score como umbral, si usaramos el score estandarizado, deberiamos de cambiar el sentido de la comparación\n",
    "users_evaluation_test['y_pred'] = np.where(users_evaluation_test['score'] >= thresh_dev, 'genuine', 'impostor')\n",
    "\n",
    "users_evaluation_test.to_excel(\"./output/outputPredRandomForestTest.xlsx\")\n",
    "\n",
    "#Presentamos el calculo de resultados\n",
    "users_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los y_test y y_pred de nuestros resultados\n",
    "y_test_test = users_evaluation_test.loc[:, \"y_test\"]\n",
    "y_pred_test = users_evaluation_test.loc[:, \"y_pred\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "### Precisión del umbral hallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561511139812722"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como genuinos por los modelos\n",
    "genuine_scores_test = list(users_evaluation_test.loc[users_evaluation_test.y_test == \"genuine\", \"score\"])\n",
    "\n",
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como impostores por los modelos\n",
    "impostor_scores_test = list(users_evaluation_test.loc[users_evaluation_test.y_test == \"impostor\", \"score\"])\n",
    "\n",
    "thresh_x, thresh_y, _ = find_fpr_and_tpr_given_a_threshold(genuine_scores_test, impostor_scores_test, thresh_dev)\n",
    "\n",
    "thresh_std = round(thresh_dev.tolist(), 3)\n",
    "\n",
    "#Ploteamos la curva ROC\n",
    "plotCurveROC_Threshold( genuine_scores_test, impostor_scores_test, thresh_std, thresh_x, thresh_y, \"black\",  title = \"ROC del modelo SVM con el dataset de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Random Forest - Modelo Usuario 1\")\n",
    "\n",
    "sc1 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 1), \"std_score\"]\n",
    "sc2 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 2), \"std_score\"]\n",
    "sc3 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 3), \"std_score\"]\n",
    "sc4 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 4), \"std_score\"]\n",
    "\n",
    "y1 = np.zeros(len(sc1))\n",
    "y2 = np.zeros(len(sc2))\n",
    "y3 = np.zeros(len(sc3))\n",
    "y4 = np.zeros(len(sc4))\n",
    "\n",
    "plt.scatter(sc1, y1, label = \"Usuario 1\")\n",
    "plt.scatter(sc2, y2, label = \"Usuario 2\")\n",
    "plt.scatter(sc3, y3, label = \"Usuario 3\")\n",
    "plt.scatter(sc4, y4, label = \"Usuario 4\")\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Random Forest - Modelo Usuario 2\")\n",
    "\n",
    "sc1 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 1), \"std_score\"]\n",
    "sc2 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 2), \"std_score\"]\n",
    "sc3 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 3), \"std_score\"]\n",
    "sc4 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 4), \"std_score\"]\n",
    "\n",
    "y1 = np.zeros(len(sc1))\n",
    "y2 = np.zeros(len(sc2))\n",
    "y3 = np.zeros(len(sc3))\n",
    "y4 = np.zeros(len(sc4))\n",
    "\n",
    "plt.scatter(sc2, y2, label = \"Usuario 2\")\n",
    "plt.scatter(sc1, y1, label = \"Usuario 1\")\n",
    "plt.scatter(sc3, y3, label = \"Usuario 3\")\n",
    "plt.scatter(sc4, y4, label = \"Usuario 4\")\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.min()[\"score\"]\n",
    "\n",
    "'{0:.0f}'.format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.max()[\"score\"]\n",
    "\n",
    "'{0:.0f}'.format(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00000000'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.min()[\"std_score\"]\n",
    "\n",
    "'{0:.8f}'.format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.00000000'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.max()[\"std_score\"]\n",
    "\n",
    "'{0:.8f}'.format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['age_bmi'] = df.age * df.bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar excel\n",
    "#users_evaluation.to_excel(\"output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
