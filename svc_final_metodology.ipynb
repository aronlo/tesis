{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score\n",
    "from scipy.spatial import distance\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo para convertir ticks a segundos\n",
    "def ticks_to_seconds(ticks):\n",
    "    return ticks / 10000000 #10'000'000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método de función para encontrar el valor más cercano en un array\n",
    "Parámetros\n",
    "----------\n",
    "array : array\n",
    "value : valor que se debe de encontrar más cercano\n",
    "\n",
    "Retorno\n",
    "-------\n",
    "Indice en el array y su valor respectivo en el array\n",
    "\"\"\"\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx, array[idx]\n",
    "\n",
    "def find_fpr_and_tpr_given_a_threshold(genuine_scores, impostor_scores, threshold):\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    fprs, tprs, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    idx, value = find_nearest(thresholds, threshold)\n",
    "    return fprs[idx], tprs[idx], value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del método para evaluar el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_Model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy )\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del método para el cálculo del AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método para el cálculo del Area Under the Curve\n",
    "Parámetros\n",
    "----------\n",
    "user_scores : array con los scores o distancias del usuario legítimo\n",
    "impostor_scores : array con los scores o distancias de usuarios ilegítimos\n",
    "\n",
    "Retorno\n",
    "-------\n",
    "AUC: area bajo la curva ROC\n",
    "\"\"\"\n",
    "def evaluate_AUC(genuine_scores, impostor_scores):\n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    auc_score = roc_auc_score(labels, genuine_scores + impostor_scores)\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Método para el cálculo del ERR\n",
    "Parámetros\n",
    "----------\n",
    "user_scores : array con los scores o distancias del usuario legítimo\n",
    "impostor_scores : array con los scores o distancias de usuarios ilegítimos\n",
    "\n",
    "Retorno\n",
    "-------\n",
    "Equal Error Rate: punto donde los missrates y los far\n",
    "\"\"\"\n",
    "#Primera forma de hallar el ERR\n",
    "def evaluate_EER(genuine_scores, impostor_scores):\n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    #Variable con los False Negative Rate (FNR) - miss\n",
    "    missrates = 1 - tpr\n",
    "    \n",
    "    #Variable con los False Positive Rate (FPR) - false alarm\n",
    "    farates = fpr\n",
    "    \n",
    "    #Se hallan las distancias entre los FNR y FPR dado cierto umbral\n",
    "    dists = missrates - farates\n",
    "    \n",
    "    #Listas que separan las distancias con los valores \n",
    "    #que estan más cercano al cero tanto superior como inferior\n",
    "    tempList1 = dists[dists >= 0]\n",
    "    tempList2 = dists[dists < 0]\n",
    "    \n",
    "    #Se busca el punto en la curva ROC donde se interceptan geométricamente el FNR y FPR\n",
    "    #El primero que sea el cercano superior al false alarm (>=)\n",
    "    #y aquel que este pegado a este en la curva pero siendo el cercano inferior (<)\n",
    "    # argmin te arroja el indice el item con los menores valores\n",
    "    # argmax te arroja el indice el item con los mayores valores\n",
    "    #idx es una variable que almacena este índice\n",
    "    \n",
    "    #Indice del menor elemento del tempList1 (Lo más pegado al cero superiormente)\n",
    "    idx1 = np.argmin(tempList1)\n",
    "    #Sacar el indice del valor de idx1 (en tempList1), pero en la lista \"dists\"\n",
    "    idx1, = np.where(dists == tempList1[idx1])\n",
    "    \n",
    "    #Indice del mayor elemento del tempList2 (Lo más pegado al cero inferiormente)\n",
    "    idx2 = np.argmax(tempList2)\n",
    "    #Sacar el indice del valor de idx2 (en tempList2), pero en la lista \"dists\"\n",
    "    idx2, = np.where(dists == tempList2[idx2])\n",
    "    \n",
    "    #Se determina es valor de los dos puntos y ponerlo en la variable x e y\n",
    "    x = [missrates[idx1], farates[idx1]]\n",
    "    y = [missrates[idx2], farates[idx2]]\n",
    "\n",
    "    #encuentrar el punto en la línea entre x e y en donde \n",
    "    #los primeros y segundos elementos del vector sean iguales.\n",
    "    #Específicamente, la línea que pasa a través de x e y \n",
    "    #se define como x + a * (y-x) para todo \"a\"\n",
    "    #Si usamos esta formula y lo igualamos, ya q x e y \n",
    "    #deben de coincidir en ese punto de la recta\n",
    "    #  -> x[1] + a*(y[1]-x[1]) = x[2] + a*(y[2]-x[2])\n",
    "    #lo factorizamos para determinar a\n",
    "    #que seria la pendiente de la recta que construiremos\n",
    "    #  -> a = (x[1] - x[2]) / (y[2]-x[2]-y[1]+x[1]) \n",
    "    \n",
    "    a = ( x[0] - x[1] ) / ( y[1] - x[1] - y[0] + x[0] )\n",
    "    eer = x[0] + a * ( y[0] - x[0] )\n",
    "    \n",
    "    return eer\n",
    "\n",
    "\n",
    "#Segunda forma de hallar el EER.\n",
    "def evaluate_EER_Thresh(genuine_scores, impostor_scores):\n",
    "    \n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1]*len(genuine_scores) + [0]*len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    #Se calcula el EER cuando el punto del fpr y del fpr se encuentran\n",
    "    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    \n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    return eer, thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del método para graficar curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCurveROC(genuine_scores, impostor_scores, title = 'Receiver Operating Characteristic'):\n",
    "    \n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    roc_auc = evaluate_AUC(genuine_scores, impostor_scores)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "def plotCurveROC_Threshold(genuine_scores, impostor_scores, threshold_value , threshold_x, threshold_y , color = \"green\" , title = 'Receiver Operating Characteristic'):\n",
    "    #Se etiquetan los usuarios legítimos con 1 e impostores con 0\n",
    "    labels = [1] * len(genuine_scores) + [0] * len(impostor_scores)\n",
    "    \n",
    "    #Se utiliza el metodo de roc_curve para hallar los fpr, tpr y umbrales\n",
    "    fpr, tpr, thresholds = roc_curve(labels, genuine_scores + impostor_scores, pos_label = 1)\n",
    "    \n",
    "    roc_auc = evaluate_AUC(genuine_scores, impostor_scores)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.scatter(threshold_x ,threshold_y, color = color)\n",
    "    plt.text(threshold_x + 0.025, threshold_y - 0.05 , threshold_value)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de archivo y eliminación de registros no válidos\n",
    "Se eliminan los registros que NO hayan escrito la palabra greyc laboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Se define la ruta donde se encuentra el archivo y se establece la conexión\n",
    "path = \"./data/grey/keystroke.db\"\n",
    "conn = sqlite3.connect(path)\n",
    "\n",
    "#Se hace la lectura y se almacena los datos extraídos en la variable df (\"dataframe\")\n",
    "df = pd.read_sql_query('select * from keystroke_datas', conn, parse_dates=['date'])\n",
    "\n",
    "#Se eliminan los registros de los usuarios que no hallan escrito la palabra 'greyc laboratory'\n",
    "df.drop(df[df['password'] != 'greyc laboratory'].index, inplace = True)\n",
    "\n",
    "#Se hace un cierre de la conexión con la base de datos SQLite\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsualización del dataset original\n",
    " El siguiente dataset contiene las siguientes columnas:\n",
    "  - ppTime: vector de tiempo entre dos teclas presionadas (press - press)\n",
    "  - rrTime: vector de tiempo entre dos teclas soltadas (release - release)\n",
    "  - prTime: vector de tiempo entre una tecla presionada y luego soltada (press - release)\n",
    "  - rpTime: vector de tiempo entre una tecla soltada y luego presionada (release - press)\n",
    "  - vector: este vector concatena todos los vectores anteriores en uno solo\n",
    "  - password: palabra escrita  por el usuario\n",
    "  - user_id: id del usuario\n",
    "  - time_to_type: tiempo que tardo en escribir la palabra\n",
    "  - rawPress: data cruda extraida de las teclas presionadas\n",
    "  - rawRelease: data cruda extraida de las teclas soltadas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ppTime</th>\n",
       "      <th>rrTime</th>\n",
       "      <th>prTime</th>\n",
       "      <th>rpTime</th>\n",
       "      <th>vector</th>\n",
       "      <th>password</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time_to_type</th>\n",
       "      <th>rawPress</th>\n",
       "      <th>rawRelease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2203168 600864 1101584 1602304 801152 2303312...</td>\n",
       "      <td>2203168 901296 500720 2503600 600864 1902736 ...</td>\n",
       "      <td>3204608 1902736 1802592 3204608 2203168 33047...</td>\n",
       "      <td>1201728 -400576 -200288 901296 -801152 901296...</td>\n",
       "      <td>2203168 600864 1101584 1602304 801152 2303312...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:09</td>\n",
       "      <td>30644064</td>\n",
       "      <td>71 633729665463844160\\n82 633729665466047328\\n...</td>\n",
       "      <td>71 633729665464845600\\n82 633729665467048768\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2103024 500720 2703888 1602304 2103024 340489...</td>\n",
       "      <td>1902736 701008 2203168 1802592 2203168 310446...</td>\n",
       "      <td>3104464 1702448 3404896 2503600 3104464 41059...</td>\n",
       "      <td>901296 -500720 1502160 901296 1201728 2403456...</td>\n",
       "      <td>2103024 500720 2703888 1602304 2103024 340489...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:18</td>\n",
       "      <td>33748528</td>\n",
       "      <td>71 633729665547564544\\n82 633729665549667568\\n...</td>\n",
       "      <td>71 633729665548766272\\n82 633729665550669008\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2203168 701008 1402016 1301872 2303312 330475...</td>\n",
       "      <td>2503600 801152 901296 1602304 2203168 3104464...</td>\n",
       "      <td>3304752 1902736 2103024 2303312 3204608 40057...</td>\n",
       "      <td>1402016 -400576 200288 600864 1301872 2403456...</td>\n",
       "      <td>2203168 701008 1402016 1301872 2303312 330475...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:28</td>\n",
       "      <td>29442336</td>\n",
       "      <td>71 633729665651914592\\n82 633729665654117760\\n...</td>\n",
       "      <td>71 633729665652715744\\n82 633729665655219344\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2103024 701008 1902736 1702448 1602304 260374...</td>\n",
       "      <td>2303312 701008 1402016 2002880 1602304 240345...</td>\n",
       "      <td>3304752 1902736 2603744 2703888 2603744 34048...</td>\n",
       "      <td>1101584 -500720 701008 1001440 600864 1602304...</td>\n",
       "      <td>2103024 701008 1902736 1702448 1602304 260374...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:48</td>\n",
       "      <td>31545360</td>\n",
       "      <td>71 633729665853404320\\n82 633729665855507344\\n...</td>\n",
       "      <td>71 633729665854405760\\n82 633729665856709072\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2002880 600864 1201728 1602304 1502160 300432...</td>\n",
       "      <td>2002880 901296 701008 1802592 1502160 2703888...</td>\n",
       "      <td>2904176 1802592 1902736 2503600 2403456 36051...</td>\n",
       "      <td>1101584 -300432 0 901296 600864 2103024 50072...</td>\n",
       "      <td>2002880 600864 1201728 1602304 1502160 300432...</td>\n",
       "      <td>greyc laboratory</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03-18 08:49:58</td>\n",
       "      <td>29642624</td>\n",
       "      <td>71 633729665954750048\\n82 633729665956752928\\n...</td>\n",
       "      <td>71 633729665955651344\\n82 633729665957654224\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             ppTime  \\\n",
       "5   6   2203168 600864 1101584 1602304 801152 2303312...   \n",
       "6   7   2103024 500720 2703888 1602304 2103024 340489...   \n",
       "7   8   2203168 701008 1402016 1301872 2303312 330475...   \n",
       "8   9   2103024 701008 1902736 1702448 1602304 260374...   \n",
       "9  10   2002880 600864 1201728 1602304 1502160 300432...   \n",
       "\n",
       "                                              rrTime  \\\n",
       "5   2203168 901296 500720 2503600 600864 1902736 ...   \n",
       "6   1902736 701008 2203168 1802592 2203168 310446...   \n",
       "7   2503600 801152 901296 1602304 2203168 3104464...   \n",
       "8   2303312 701008 1402016 2002880 1602304 240345...   \n",
       "9   2002880 901296 701008 1802592 1502160 2703888...   \n",
       "\n",
       "                                              prTime  \\\n",
       "5   3204608 1902736 1802592 3204608 2203168 33047...   \n",
       "6   3104464 1702448 3404896 2503600 3104464 41059...   \n",
       "7   3304752 1902736 2103024 2303312 3204608 40057...   \n",
       "8   3304752 1902736 2603744 2703888 2603744 34048...   \n",
       "9   2904176 1802592 1902736 2503600 2403456 36051...   \n",
       "\n",
       "                                              rpTime  \\\n",
       "5   1201728 -400576 -200288 901296 -801152 901296...   \n",
       "6   901296 -500720 1502160 901296 1201728 2403456...   \n",
       "7   1402016 -400576 200288 600864 1301872 2403456...   \n",
       "8   1101584 -500720 701008 1001440 600864 1602304...   \n",
       "9   1101584 -300432 0 901296 600864 2103024 50072...   \n",
       "\n",
       "                                              vector          password  \\\n",
       "5   2203168 600864 1101584 1602304 801152 2303312...  greyc laboratory   \n",
       "6   2103024 500720 2703888 1602304 2103024 340489...  greyc laboratory   \n",
       "7   2203168 701008 1402016 1301872 2303312 330475...  greyc laboratory   \n",
       "8   2103024 701008 1902736 1702448 1602304 260374...  greyc laboratory   \n",
       "9   2002880 600864 1201728 1602304 1502160 300432...  greyc laboratory   \n",
       "\n",
       "   user_id                date  time_to_type  \\\n",
       "5        1 2009-03-18 08:49:09      30644064   \n",
       "6        1 2009-03-18 08:49:18      33748528   \n",
       "7        1 2009-03-18 08:49:28      29442336   \n",
       "8        1 2009-03-18 08:49:48      31545360   \n",
       "9        1 2009-03-18 08:49:58      29642624   \n",
       "\n",
       "                                            rawPress  \\\n",
       "5  71 633729665463844160\\n82 633729665466047328\\n...   \n",
       "6  71 633729665547564544\\n82 633729665549667568\\n...   \n",
       "7  71 633729665651914592\\n82 633729665654117760\\n...   \n",
       "8  71 633729665853404320\\n82 633729665855507344\\n...   \n",
       "9  71 633729665954750048\\n82 633729665956752928\\n...   \n",
       "\n",
       "                                          rawRelease  \n",
       "5  71 633729665464845600\\n82 633729665467048768\\n...  \n",
       "6  71 633729665548766272\\n82 633729665550669008\\n...  \n",
       "7  71 633729665652715744\\n82 633729665655219344\\n...  \n",
       "8  71 633729665854405760\\n82 633729665856709072\\n...  \n",
       "9  71 633729665955651344\\n82 633729665957654224\\n...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de vectores de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Variable temporal para almacenar los items de la columna vector\n",
    "#ya que no se puede trabajar directamente con ese formato\n",
    "tempData = []\n",
    "\n",
    "#Variable con la cantidad de registros totales de la bd\n",
    "n_data_rows = df.shape[0]\n",
    "\n",
    "#Variable que tendrá la lista de columnas del dataframe\n",
    "columns = [\"user_id\"]   \n",
    "\n",
    "#Como existen en total 60 features de tiempo por usuario, se generará \n",
    "#los nombres de las columnas siguiento el siguiente formato \n",
    "#=> 'ft_'   +  posición del feature en el vector\n",
    "for i in range(60):\n",
    "    columns.append(\"ft_\" + str(i+1))\n",
    "\n",
    "#Por cada registro que existe en la bd se aplica lo siguente\n",
    "for i in range(n_data_rows):\n",
    "    \n",
    "    #Se extrae el usuario de ese registro\n",
    "    user_id = [df.iloc[i][\"user_id\"]]\n",
    "    #Se extrae el tiempo de tecleo\n",
    "    time_to_type = [df.iloc[i][\"time_to_type\"]]\n",
    "    \n",
    "    #Se crea el vector de tiempo\n",
    "    vector = df.iloc[i][\"vector\"].split()      \n",
    " \n",
    "    #Se verifica que la integridad del vector este OK,\n",
    "    #es decir que tenga una longitud exacta de 60 items\n",
    "    if(len(vector) == 60 ):\n",
    "        #Se aprega el registro a la variable temporarl tempData si cumple con la condición de integridad\n",
    "        tempData.append(user_id  + list(map(int, vector)))\n",
    "\n",
    "#Se crea el dataframe y se asigna a la variable df\n",
    "df = pd.DataFrame(tempData, columns = columns)\n",
    "\n",
    "#Conversion de tick a segundos \n",
    "features = df.columns[1:61]\n",
    "for i in range(len(features)):\n",
    "    col = features[i]\n",
    "    df[col] = df[col].apply(lambda x: ticks_to_seconds(x))\n",
    "\n",
    "#Se liberan recursos de la variable\n",
    "tempData.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsualización de dataset procesado\n",
    "Por cada registro, se tienen las siguientes columnas\n",
    " - Los features entre el 1 y 12 corresponden al vector de tiempo ppTime\n",
    " - Los features entre el 13 y 25 corresponden al vector de tiempo rrTime\n",
    " - Los features entre el 26 y 37 corresponden al vector de tiempo prTime\n",
    " - Los features entre el 38 y 60 corresponden al vector de tiempo rpTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.210302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.210302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.390562</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.260374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.240346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.390562</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.220317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id      ft_1      ft_2      ft_3      ft_4      ft_5      ft_6  \\\n",
       "0        1  0.220317  0.060086  0.110158  0.160230  0.080115  0.230331   \n",
       "1        1  0.210302  0.050072  0.270389  0.160230  0.210302  0.340490   \n",
       "2        1  0.220317  0.070101  0.140202  0.130187  0.230331  0.330475   \n",
       "3        1  0.210302  0.070101  0.190274  0.170245  0.160230  0.260374   \n",
       "4        1  0.200288  0.060086  0.120173  0.160230  0.150216  0.300432   \n",
       "\n",
       "       ft_7      ft_8      ft_9  ...     ft_51     ft_52     ft_53     ft_54  \\\n",
       "0  0.100144  0.260374  0.140202  ...  0.330475  0.200288  0.360518  0.200288   \n",
       "1  0.140202  0.260374  0.140202  ...  0.410590  0.230331  0.350504  0.210302   \n",
       "2  0.090130  0.300432  0.150216  ...  0.400576  0.190274  0.390562  0.220317   \n",
       "3  0.150216  0.300432  0.150216  ...  0.340490  0.270389  0.400576  0.220317   \n",
       "4  0.110158  0.290418  0.160230  ...  0.360518  0.220317  0.390562  0.230331   \n",
       "\n",
       "      ft_55     ft_56     ft_57     ft_58     ft_59     ft_60  \n",
       "0  0.280403  0.240346  0.290418  0.240346  0.230331  0.210302  \n",
       "1  0.220317  0.260374  0.280403  0.260374  0.310446  0.210302  \n",
       "2  0.230331  0.310446  0.260374  0.220317  0.220317  0.260374  \n",
       "3  0.230331  0.240346  0.310446  0.210302  0.290418  0.240346  \n",
       "4  0.260374  0.310446  0.260374  0.190274  0.250360  0.220317  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separación de la data de entrenamiento y de prueba\n",
    "Se toma de forma aleatoria el 80% de los registros de cada usuario para considerarlos como data de entrenamiento, el 10%  para la data de desarrollo del umbral y el 10 % restante para la data de prueba\n",
    "\n",
    "\n",
    "La función train_test_split cuando existe un grupo impar, siempre el último subgrupo recibe el elemento extra.\n",
    "Se trató de redondear el 0.80 del parámetro **train_size** debido a que cuando se trabaja con esta cantidad, arrojaba una mayor cantidad de splits con subdatasets de dev y de test desiguales. Aproximandamente **73**\n",
    "![Resultados usando una proporcion de 80](./img/Proportion%20split%2080.png)\n",
    "\n",
    "Poner 0.84 en el parámetro **train_size** permite tener menores grupos de subdatasets de dev y de test desiguales. En este solo se obtienen **4** de este tipo.\n",
    "> Se debe de mantener que el dataset de dev sea lo más similar al de test.\n",
    "\n",
    "[Link de fuente](https://cs230.stanford.edu/blog/split/)\n",
    "\n",
    "![Resultados usando una proporcion de 84](./img/Proportion%20split%2084.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable que contiene la lista de todos los usuarios de la bd\n",
    "subjects = df[\"user_id\"].unique()\n",
    "\n",
    "#Variable del dataset de train 80%\n",
    "train_users = []\n",
    "\n",
    "#Variable del dataset de dev (desarrollo) para el calculo del umbral 10%\n",
    "dev_users = []\n",
    "\n",
    "#Variable del dataset de test 10%\n",
    "test_users = []\n",
    "\n",
    "#Separar el df en 80 / 10 / 20 respectivamente y asignarlo a sus \n",
    "for subject in subjects:\n",
    "    current_user_data = df.loc[df.user_id == subject, :]\n",
    "            \n",
    "    #impostor_data = df.loc[df.user_id != subject, :]\n",
    "    \n",
    "    #Caso especial de una proporcion de 60/20/20 cuando el usuario tiene solo 5 registros\n",
    "    #Para no eliminar ese registro y no lanze error \n",
    "    #Donde quedaría asi 5 -> 3 / 1 / 1\n",
    "\n",
    "    if len(current_user_data) == 5:\n",
    "        train, dev = train_test_split(current_user_data, train_size = 0.6, random_state=43, shuffle=True)\n",
    "        dev , test = train_test_split(dev, train_size = 0.5, random_state=43, shuffle=True)\n",
    "    \n",
    "    #Caso contrario se respeta la proporcion de 80/10/10 establecida antes\n",
    "    else:\n",
    "        train, dev = train_test_split(current_user_data, train_size = 0.80, random_state=43, shuffle=True)\n",
    "        dev , test = train_test_split(dev, train_size = 0.5, random_state=43, shuffle=True)\n",
    "        \n",
    "    #Se agregan a los 3 datasets los splits calculados aleatoriamente\n",
    "    train_users.append(train)\n",
    "    dev_users.append(dev)\n",
    "    test_users.append(test)\n",
    "\n",
    "#Se convierte los arrays en dataframes manipulables\n",
    "train_users = pd.concat(train_users)\n",
    "dev_users = pd.concat(dev_users)\n",
    "test_users = pd.concat(test_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsualización del dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.160230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.430619</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>1</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.160230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>1</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.190274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.170245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7483</th>\n",
       "      <td>133</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.640922</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.370533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>133</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.390562</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470677</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.771109</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.390562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>133</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.520749</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.350504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7308</th>\n",
       "      <td>133</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.560806</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640922</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.510734</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.380547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7312</th>\n",
       "      <td>133</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.550792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5991 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id      ft_1      ft_2      ft_3      ft_4      ft_5      ft_6  \\\n",
       "4797        1  0.210302  0.070101  0.260374  0.100144  0.100144  0.200288   \n",
       "12          1  0.240346  0.060086  0.140202  0.160230  0.080115  0.210302   \n",
       "3959        1  0.190274  0.070101  0.100144  0.080115  0.100144  0.190274   \n",
       "6799        1  0.200288  0.070101  0.100144  0.130187  0.100144  0.210302   \n",
       "2222        1  0.210302  0.070101  0.090130  0.120173  0.070101  0.240346   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "7483      133  0.330475  0.240346  0.230331  0.190274  0.170245  0.220317   \n",
       "7480      133  0.190274  0.200288  0.210302  0.210302  0.170245  0.390562   \n",
       "7481      133  0.220317  0.180259  0.220317  0.160230  0.140202  0.260374   \n",
       "7308      133  0.190274  0.200288  0.190274  0.200288  0.190274  0.560806   \n",
       "7312      133  0.200288  0.210302  0.300432  0.260374  0.150216  0.190274   \n",
       "\n",
       "          ft_7      ft_8      ft_9  ...     ft_51     ft_52     ft_53  \\\n",
       "4797  0.050072  0.240346  0.140202  ...  0.300432  0.170245  0.360518   \n",
       "12    0.120173  0.300432  0.170245  ...  0.320461  0.230331  0.430619   \n",
       "3959  0.050072  0.260374  0.090130  ...  0.260374  0.170245  0.340490   \n",
       "6799  0.170245  0.160230  0.290418  ...  0.290418  0.280403  0.240346   \n",
       "2222  0.100144  0.210302  0.140202  ...  0.340490  0.190274  0.330475   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7483  0.210302  0.190274  0.240346  ...  0.340490  0.300432  0.310446   \n",
       "7480  0.190274  0.230331  0.220317  ...  0.470677  0.280403  0.330475   \n",
       "7481  0.220317  0.210302  0.160230  ...  0.380547  0.320461  0.300432   \n",
       "7308  0.180259  0.120173  0.190274  ...  0.640922  0.260374  0.200288   \n",
       "7312  0.160230  0.180259  0.210302  ...  0.300432  0.270389  0.270389   \n",
       "\n",
       "         ft_54     ft_55     ft_56     ft_57     ft_58     ft_59     ft_60  \n",
       "4797  0.220317  0.270389  0.160230  0.220317  0.170245  0.340490  0.160230  \n",
       "12    0.250360  0.260374  0.270389  0.270389  0.210302  0.260374  0.220317  \n",
       "3959  0.160230  0.290418  0.240346  0.210302  0.140202  0.250360  0.160230  \n",
       "6799  0.400576  0.330475  0.260374  0.260374  0.180259  0.270389  0.190274  \n",
       "2222  0.210302  0.310446  0.270389  0.250360  0.160230  0.300432  0.170245  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7483  0.330475  0.640922  0.310446  0.330475  0.190274  0.240346  0.370533  \n",
       "7480  0.310446  0.280403  0.320461  0.771109  0.340490  0.250360  0.390562  \n",
       "7481  0.280403  0.290418  0.280403  0.520749  0.260374  0.260374  0.350504  \n",
       "7308  0.310446  0.330475  0.360518  0.510734  0.260374  0.300432  0.380547  \n",
       "7312  0.340490  0.440634  0.360518  0.410590  0.260374  0.310446  0.550792  \n",
       "\n",
       "[5991 rows x 61 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsualización del dataset de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.040058</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.210302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>1</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.230331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.250360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.440634</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.250360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.060086</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.210302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>132</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.290418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7359</th>\n",
       "      <td>132</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.550792</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>1.031483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7140</th>\n",
       "      <td>132</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450648</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.690994</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.410590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7314</th>\n",
       "      <td>133</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.560806</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.360518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>133</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.600864</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.951368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id      ft_1      ft_2      ft_3      ft_4      ft_5      ft_6  \\\n",
       "11          1  0.220317  0.040058  0.270389  0.180259  0.170245  0.290418   \n",
       "4789        1  0.190274  0.070101  0.150216  0.110158  0.070101  0.240346   \n",
       "2323        1  0.220317  0.070101  0.130187  0.110158  0.080115  0.230331   \n",
       "8           1  0.210302  0.060086  0.120173  0.170245  0.310446  0.240346   \n",
       "0           1  0.220317  0.060086  0.110158  0.160230  0.080115  0.230331   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "7148      132  0.210302  0.150216  0.180259  0.160230  0.160230  0.290418   \n",
       "7359      132  0.210302  0.120173  0.160230  0.160230  0.170245  0.260374   \n",
       "7140      132  0.230331  0.150216  0.220317  0.180259  0.200288  0.380547   \n",
       "7314      133  0.190274  0.210302  0.560806  0.280403  0.130187  0.190274   \n",
       "7487      133  0.170245  0.190274  0.190274  0.210302  0.140202  0.220317   \n",
       "\n",
       "          ft_7      ft_8      ft_9  ...     ft_51     ft_52     ft_53  \\\n",
       "11    0.130187  0.310446  0.120173  ...  0.360518  0.230331  0.410590   \n",
       "4789  0.100144  0.210302  0.120173  ...  0.360518  0.220317  0.330475   \n",
       "2323  0.050072  0.250360  0.150216  ...  0.330475  0.180259  0.370533   \n",
       "8     0.140202  0.350504  0.150216  ...  0.320461  0.250360  0.440634   \n",
       "0     0.100144  0.260374  0.140202  ...  0.330475  0.200288  0.360518   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7148  0.160230  0.140202  0.190274  ...  0.370533  0.260374  0.220317   \n",
       "7359  0.140202  0.180259  0.140202  ...  0.340490  0.240346  0.240346   \n",
       "7140  0.140202  0.190274  0.170245  ...  0.450648  0.250360  0.280403   \n",
       "7314  0.140202  0.170245  0.210302  ...  0.300432  0.260374  0.280403   \n",
       "7487  0.230331  0.140202  0.220317  ...  0.310446  0.350504  0.260374   \n",
       "\n",
       "         ft_54     ft_55     ft_56     ft_57     ft_58     ft_59     ft_60  \n",
       "11    0.220317  0.240346  0.250360  0.260374  0.220317  0.270389  0.210302  \n",
       "4789  0.210302  0.330475  0.250360  0.240346  0.170245  0.300432  0.230331  \n",
       "2323  0.230331  0.300432  0.290418  0.270389  0.220317  0.270389  0.250360  \n",
       "8     0.220317  0.240346  0.250360  0.270389  0.180259  0.260374  0.250360  \n",
       "0     0.200288  0.280403  0.240346  0.290418  0.240346  0.230331  0.210302  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7148  0.260374  0.330475  0.230331  0.120173  0.380547  0.360518  0.290418  \n",
       "7359  0.220317  0.340490  0.240346  0.140202  0.550792  0.360518  1.031483  \n",
       "7140  0.250360  0.370533  0.270389  0.190274  0.690994  0.300432  0.410590  \n",
       "7314  0.330475  0.310446  0.290418  0.360518  0.240346  0.230331  0.360518  \n",
       "7487  0.340490  0.280403  0.300432  0.600864  0.220317  0.290418  0.951368  \n",
       "\n",
       "[742 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previsualización del dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_6</th>\n",
       "      <th>ft_7</th>\n",
       "      <th>ft_8</th>\n",
       "      <th>ft_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_51</th>\n",
       "      <th>ft_52</th>\n",
       "      <th>ft_53</th>\n",
       "      <th>ft_54</th>\n",
       "      <th>ft_55</th>\n",
       "      <th>ft_56</th>\n",
       "      <th>ft_57</th>\n",
       "      <th>ft_58</th>\n",
       "      <th>ft_59</th>\n",
       "      <th>ft_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6795</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.040058</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.130187</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.230331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>1</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.150216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>1</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.110158</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.160230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.420605</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.230331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.080115</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.190274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>132</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.530763</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.340490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>132</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.430619</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.240346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>133</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.480691</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.580835</td>\n",
       "      <td>0.260374</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.240346</td>\n",
       "      <td>0.350504</td>\n",
       "      <td>0.420605</td>\n",
       "      <td>0.290418</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.390562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7313</th>\n",
       "      <td>133</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.120173</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.210302</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.500720</td>\n",
       "      <td>0.430619</td>\n",
       "      <td>0.400576</td>\n",
       "      <td>0.380547</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.320461</td>\n",
       "      <td>0.410590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>133</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.190274</td>\n",
       "      <td>0.230331</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.200288</td>\n",
       "      <td>0.160230</td>\n",
       "      <td>0.170245</td>\n",
       "      <td>0.300432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310446</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.280403</td>\n",
       "      <td>0.410590</td>\n",
       "      <td>0.370533</td>\n",
       "      <td>0.420605</td>\n",
       "      <td>0.360518</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.460662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id      ft_1      ft_2      ft_3      ft_4      ft_5      ft_6  \\\n",
       "6795        1  0.250360  0.040058  0.190274  0.120173  0.070101  0.220317   \n",
       "3954        1  0.170245  0.070101  0.110158  0.090130  0.070101  0.200288   \n",
       "6802        1  0.190274  0.070101  0.150216  0.110158  0.090130  0.220317   \n",
       "405         1  0.160230  0.090130  0.090130  0.170245  0.090130  0.180259   \n",
       "4791        1  0.250360  0.080115  0.210302  0.120173  0.100144  0.210302   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "6751      132  0.200288  0.140202  0.160230  0.180259  0.160230  0.280403   \n",
       "6754      132  0.210302  0.170245  0.190274  0.140202  0.170245  0.280403   \n",
       "7477      133  0.210302  0.290418  0.350504  0.380547  0.120173  0.210302   \n",
       "7313      133  0.220317  0.180259  0.170245  0.120173  0.190274  0.190274   \n",
       "7318      133  0.190274  0.190274  0.230331  0.170245  0.170245  0.200288   \n",
       "\n",
       "          ft_7      ft_8      ft_9  ...     ft_51     ft_52     ft_53  \\\n",
       "6795  0.130187  0.230331  0.280403  ...  0.310446  0.260374  0.340490   \n",
       "3954  0.050072  0.230331  0.090130  ...  0.280403  0.160230  0.340490   \n",
       "6802  0.120173  0.190274  0.260374  ...  0.320461  0.240346  0.290418   \n",
       "405   0.120173  0.260374  0.140202  ...  0.300432  0.230331  0.420605   \n",
       "4791  0.120173  0.240346  0.180259  ...  0.300432  0.240346  0.380547   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6751  0.160230  0.150216  0.210302  ...  0.360518  0.280403  0.220317   \n",
       "6754  0.190274  0.160230  0.200288  ...  0.380547  0.280403  0.260374   \n",
       "7477  0.480691  0.140202  0.260374  ...  0.330475  0.580835  0.260374   \n",
       "7313  0.210302  0.140202  0.400576  ...  0.330475  0.300432  0.190274   \n",
       "7318  0.160230  0.170245  0.300432  ...  0.310446  0.280403  0.280403   \n",
       "\n",
       "         ft_54     ft_55     ft_56     ft_57     ft_58     ft_59     ft_60  \n",
       "6795  0.370533  0.320461  0.240346  0.290418  0.190274  0.320461  0.230331  \n",
       "3954  0.170245  0.280403  0.220317  0.220317  0.160230  0.260374  0.150216  \n",
       "6802  0.330475  0.290418  0.260374  0.230331  0.110158  0.280403  0.160230  \n",
       "405   0.240346  0.310446  0.260374  0.250360  0.240346  0.250360  0.230331  \n",
       "4791  0.250360  0.310446  0.280403  0.280403  0.170245  0.350504  0.190274  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6751  0.290418  0.330475  0.260374  0.170245  0.530763  0.370533  0.340490  \n",
       "6754  0.290418  0.360518  0.240346  0.190274  0.430619  0.350504  0.240346  \n",
       "7477  0.380547  0.240346  0.350504  0.420605  0.290418  0.280403  0.390562  \n",
       "7313  0.500720  0.430619  0.400576  0.380547  0.270389  0.320461  0.410590  \n",
       "7318  0.410590  0.370533  0.420605  0.360518  0.270389  0.330475  0.460662  \n",
       "\n",
       "[815 rows x 61 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de las probablidades con los registros de DESARROLLO\n",
    "\n",
    "![Calculo de distancias](./img/Calculo%20de%20distancias.png)\n",
    "\n",
    "### Ejemplo del usuario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de los datos a usar para el usuario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aca obtenemos el X_train, y_train del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos una copia temporal del dataset de entrenamiento\n",
    "temp1 = train_users.copy()\n",
    "\n",
    "#Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "temp1[\"user_id\"] = temp1[\"user_id\"].mask(temp1[\"user_id\"] != 1, 0)\n",
    "\n",
    "#Obtenemos los registros considerados genuinos del entrenamiento\n",
    "genuine_data = temp1.loc[temp1.user_id == 1, :]\n",
    "\n",
    "#Obtenemos los registros considerados impostores del entrenamiento.\n",
    "#Este debe de ser del mismo tamaño que de los registros genuinos\n",
    "impostor_data = temp1.loc[temp1.user_id != 1, :].sample(n= genuine_data.shape[0], random_state=43)\n",
    "\n",
    "#Lo unimos los dos anteriores en un solo dataset de entrenamiento del modelo del usuario 1\n",
    "train = pd.concat([genuine_data, impostor_data])\n",
    "\n",
    "#Obtenemos el X_train\n",
    "X_train = train.loc[:, \"ft_1\":\"ft_60\" ]\n",
    "\n",
    "#Obtenemos el y_train\n",
    "y_train = train.loc[:, \"user_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtenemos el X_dev , y_dev, X_test y y_test del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos una copia temporal del dataset de desarrollo\n",
    "temp2 = dev_users.copy()\n",
    "\n",
    "#Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "temp2[\"user_id\"] = temp2[\"user_id\"].mask(temp2[\"user_id\"] != 1, 0)\n",
    "\n",
    "#df.sample(frac=0.5, replace=True, random_state=1)\n",
    "X_dev = temp2.loc[:, \"ft_1\":\"ft_60\"]\n",
    "y_dev = temp2.loc[:, \"user_id\"]\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "#Generamos una copia temporal del dataset de test\n",
    "temp3 = test_users.copy()\n",
    "\n",
    "#Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "temp3[\"user_id\"] = temp3[\"user_id\"].mask(temp3[\"user_id\"] != 1, 0)\n",
    "\n",
    "X_test = temp3.loc[:, \"ft_1\":\"ft_60\"]\n",
    "y_test = temp3.loc[:, \"user_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos la busqueda de los mejores hiperparámetros\n",
    "Comenzamos con un Grid Search para hallar los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0,\n",
      " 'break_ties': False,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'scale',\n",
      " 'kernel': 'rbf',\n",
      " 'max_iter': -1,\n",
      " 'probability': False,\n",
      " 'random_state': None,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "#Creamos un modelo SVC\n",
    "svc = SVC()\n",
    "\n",
    "#Mostramos parametros por default\n",
    "pprint(svc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0],\n",
      " 'gamma': [1.0,\n",
      "           0.1,\n",
      "           0.01,\n",
      "           0.001,\n",
      "           0.0001,\n",
      "           1e-05,\n",
      "           1e-06,\n",
      "           1e-07,\n",
      "           1e-08,\n",
      "           1e-09,\n",
      "           'scale'],\n",
      " 'kernel': ['linear', 'rbf']}\n"
     ]
    }
   ],
   "source": [
    "C = [x for x in np.geomspace(0.01, 100000, num=8)]\n",
    "kernel = ['linear', 'rbf']\n",
    "gamma = [x for x in np.geomspace(1, 0.000000001, num=10)]\n",
    "gamma.append('scale')\n",
    "\n",
    "param_grid = {\n",
    "    'C': C, \n",
    "    'gamma': gamma,\n",
    "    'kernel': kernel}\n",
    "\n",
    "#Hiperparametros a evaluar\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 176 candidates, totalling 880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 880 out of 880 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Realizamos el grid search\n",
    "grid_search  = GridSearchCV(SVC(), param_grid, verbose=1, cv = 5, n_jobs = -1)\n",
    "\n",
    "grid_search .fit(X_train,y_train)\n",
    "\n",
    "#Mejores hiperparametros\n",
    "grid_search.best_params_\n",
    "\n",
    "#Accuracy\n",
    "#grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con los parámetros por default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9743935309973046\n"
     ]
    }
   ],
   "source": [
    "base_model = SVC()\n",
    "base_model.fit(X_train,y_train)\n",
    "base_accuracy = evaluate_Model(base_model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados con los parámetros encontrados por el Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9757412398921833\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate_Model(best_grid, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo con mejores hiperparametros  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=43, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos el modelo SVC\n",
    "clf = SVC(C = 10.0, gamma = 'scale', kernel = 'rbf', probability = True, random_state=43)\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos las predicciones\n",
    "y_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado con el subdataset de prueba del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9905660377358491\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de las probabilidades de cada registro usando el modelo del usuario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probImpos</th>\n",
       "      <th>probLegi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.276408</td>\n",
       "      <td>0.723592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006957</td>\n",
       "      <td>0.993043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.995238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.371290</td>\n",
       "      <td>0.628710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043535</td>\n",
       "      <td>0.956465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.972352</td>\n",
       "      <td>0.027648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0.995616</td>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.996406</td>\n",
       "      <td>0.003594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     probImpos  probLegi\n",
       "0     0.276408  0.723592\n",
       "1     0.006957  0.993043\n",
       "2     0.004762  0.995238\n",
       "3     0.371290  0.628710\n",
       "4     0.043535  0.956465\n",
       "..         ...       ...\n",
       "737   0.972352  0.027648\n",
       "738   0.995616  0.004384\n",
       "739   0.999225  0.000775\n",
       "740   0.999847  0.000153\n",
       "741   0.996406  0.003594\n",
       "\n",
       "[742 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Con la función predict_proba obtenemos las probabilidades para cada clase.\n",
    "#En el primero, obtenemos la probalidad de que sea un registro de un usuario impostor\n",
    "#En el otro, obtenemos la probalidad de que el registro pertenesca al usuario 1 (legitimo)\n",
    "y_prob = clf.predict_proba(X_dev)\n",
    "y_prob = pd.DataFrame(y_prob, columns = [\"probImpos\", \"probLegi\"])\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable donde se almacenará toda la informacion calculada del usuario 1 \n",
    "user_1_evaluation_dev = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "#Para cada registro del subdataset de test\n",
    "for index, row in dev_users.iterrows():\n",
    "    \n",
    "    temp_obj = {}\n",
    "    \n",
    "    #user id del registro actual del subdataset de test\n",
    "    current_user_id = row[0]\n",
    "    \n",
    "    #Vector de tiempo del registro actual del subdataset de test\n",
    "    current_data = row[1:]\n",
    "    \n",
    "    #Actual modelo del usuario a evaluar\n",
    "    temp_obj[\"user_model\"] = 1\n",
    "\n",
    "    #user id del registro actual\n",
    "    temp_obj[\"user_id\"] = current_user_id\n",
    "    \n",
    "    #Puntaje o score del modelo\n",
    "    temp_obj[\"score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "    #Normalizacion del score\n",
    "    temp_obj[\"std_score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "    \n",
    "    #Variable que indica si el registro deberia de ser clasificado como geniono o impostor\n",
    "    if current_user_id == 1:\n",
    "        temp_obj[\"y_test\"] = \"genuine\"\n",
    "    else:\n",
    "        temp_obj[\"y_test\"] = \"impostor\"\n",
    "    \n",
    "    user_1_evaluation_dev.append(temp_obj)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "user_1_evaluation_dev = pd.DataFrame(user_1_evaluation_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntaje de los registros del subdataset de desarrollo usando el modelo del usuario 1\n",
    " - **user_model:** modelo del usuario empleado para sacar el score\n",
    " - **user_id:** usuario del registro evaluado\n",
    " - **score:** puntuación que le dió el modelo\n",
    " - **std_score:** puntuación normalizada\n",
    " - **y_test:** cuando el user_model y user_id **(1)** coinciden, entonces se usó un registro de usuario considerado genuino; caso contrario, es de un impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723592</td>\n",
       "      <td>0.723592</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993043</td>\n",
       "      <td>0.993043</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.628710</td>\n",
       "      <td>0.628710</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956465</td>\n",
       "      <td>0.956465</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.027648</td>\n",
       "      <td>0.027648</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_model  user_id     score  std_score    y_test\n",
       "0             1      1.0  0.723592   0.723592   genuine\n",
       "1             1      1.0  0.993043   0.993043   genuine\n",
       "2             1      1.0  0.995238   0.995238   genuine\n",
       "3             1      1.0  0.628710   0.628710   genuine\n",
       "4             1      1.0  0.956465   0.956465   genuine\n",
       "..          ...      ...       ...        ...       ...\n",
       "737           1    132.0  0.027648   0.027648  impostor\n",
       "738           1    132.0  0.004384   0.004384  impostor\n",
       "739           1    132.0  0.000775   0.000775  impostor\n",
       "740           1    133.0  0.000153   0.000153  impostor\n",
       "741           1    133.0  0.003594   0.003594  impostor\n",
       "\n",
       "[742 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_1_evaluation_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo usando los modelos de todos los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_evaluation_dev = []\n",
    "\n",
    "#Se hace el cálculo para cada usuario\n",
    "for subject in subjects:\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    #Generamos una copia temporal del dataset de entrenamiento\n",
    "    temp1 = train_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al sujeto actual por 0\n",
    "    temp1[\"user_id\"] = temp1[\"user_id\"].mask(temp1[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #Obtenemos los registros considerados genuinos del entrenamiento\n",
    "    genuine_data = temp1.loc[temp1.user_id == subject, :]\n",
    "\n",
    "    #Obtenemos los registros considerados impostores del entrenamiento.\n",
    "    #Este debe de ser del mismo tamaño que de los registros genuinos\n",
    "    impostor_data = temp1.loc[temp1.user_id != subject, :].sample(n= genuine_data.shape[0], random_state=43)\n",
    "\n",
    "    #Unimos los dos anteriores variables en un solo dataset de entrenamiento del modelo\n",
    "    train = pd.concat([genuine_data, impostor_data])\n",
    "\n",
    "    #Obtenemos el X_train\n",
    "    X_train = train.loc[:, \"ft_1\":\"ft_60\" ]\n",
    "\n",
    "    #Obtenemos el y_train\n",
    "    y_train = train.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Generamos una copia temporal del dataset de desarrollo\n",
    "    temp2 = dev_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp2[\"user_id\"] = temp2[\"user_id\"].mask(temp2[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #df.sample(frac=0.5, replace=True, random_state=1)\n",
    "    X_dev = temp2.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_dev = temp2.loc[:, \"user_id\"]\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "\n",
    "    #Generamos una copia temporal del dataset de test\n",
    "    temp3 = test_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp3[\"user_id\"] = temp3[\"user_id\"].mask(temp3[\"user_id\"] != subject, 0)\n",
    "\n",
    "    X_test = temp3.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_test = temp3.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Entrenamos el modelo SVM\n",
    "    \n",
    "    clf = SVC(C = 10.0, gamma = 'scale', kernel = 'rbf', probability = True, random_state=43)\n",
    "    #clf = SVC(probability = True)\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Obtenemos probabilidades de cada registro del dataset de test\n",
    "    y_prob = clf.predict_proba(X_dev)\n",
    "    y_prob = pd.DataFrame(y_prob, columns = [\"probImpos\", \"probLegi\"])\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    #Para cada registro del subdataset de test\n",
    "    for index, row in dev_users.iterrows():\n",
    "\n",
    "        temp_obj = {}\n",
    "\n",
    "        #user id del registro actual del subdataset de test\n",
    "        current_user_id = row[0]\n",
    "\n",
    "        #Vector de tiempo del registro actual del subdataset de test\n",
    "        current_data = row[1:]\n",
    "\n",
    "        #Actual modelo del usuario a evaluar\n",
    "        temp_obj[\"user_model\"] = subject\n",
    "\n",
    "        #user id del registro actual\n",
    "        temp_obj[\"user_id\"] = current_user_id\n",
    "\n",
    "        #Puntaje o score del modelo\n",
    "        temp_obj[\"score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Normalizacion del score\n",
    "        temp_obj[\"std_score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Variable que indica si el registro deberia de ser clasificado como genuino o impostor\n",
    "        if current_user_id == subject:\n",
    "            temp_obj[\"y_test\"] = \"genuine\"\n",
    "        else:\n",
    "            temp_obj[\"y_test\"] = \"impostor\"\n",
    "\n",
    "        users_evaluation_dev.append(temp_obj)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "users_evaluation_dev = pd.DataFrame(users_evaluation_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntaje de los registros del subdataset de desarrollo usando todos los modelos\n",
    " - **user_model:** modelo del usuario empleado para sacar el score\n",
    " - **user_id:** usuario del registro evaluado\n",
    " - **score:** puntuación que le dió el modelo\n",
    " - **std_score:** puntuación normalizada\n",
    " - **y_test:** cuando el user_model y user_id coinciden, entonces se usó un registro de usuario considerado genuino; caso contrario, es de un impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723592</td>\n",
       "      <td>0.723592</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993043</td>\n",
       "      <td>0.993043</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.628710</td>\n",
       "      <td>0.628710</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956465</td>\n",
       "      <td>0.956465</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98681</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.048895</td>\n",
       "      <td>0.048895</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98682</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.297178</td>\n",
       "      <td>0.297178</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98683</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98684</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98685</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.744996</td>\n",
       "      <td>0.744996</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98686 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_model  user_id     score  std_score    y_test\n",
       "0               1      1.0  0.723592   0.723592   genuine\n",
       "1               1      1.0  0.993043   0.993043   genuine\n",
       "2               1      1.0  0.995238   0.995238   genuine\n",
       "3               1      1.0  0.628710   0.628710   genuine\n",
       "4               1      1.0  0.956465   0.956465   genuine\n",
       "...           ...      ...       ...        ...       ...\n",
       "98681         133    132.0  0.048895   0.048895  impostor\n",
       "98682         133    132.0  0.297178   0.297178  impostor\n",
       "98683         133    132.0  0.049806   0.049806  impostor\n",
       "98684         133    133.0  0.500000   0.500000   genuine\n",
       "98685         133    133.0  0.744996   0.744996   genuine\n",
       "\n",
       "[98686 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_evaluation_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como genuinos por los modelos\n",
    "genuine_scores_dev = list(users_evaluation_dev.loc[users_evaluation_dev.y_test == \"genuine\", \"score\"])\n",
    "\n",
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como impostores por los modelos\n",
    "impostor_scores_dev = list(users_evaluation_dev.loc[users_evaluation_dev.y_test == \"impostor\", \"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo del umbral de decisión con el subdataset de DESARROLLO\n",
    "\n",
    "Buscamos el punto en donde los falsos negativos y los falsos positivos son iguales en los modelos de manera global\n",
    "![Calculo de umbral](./img/Calculo%20del%20umbral.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculo del ERR y del umbral de decisión global\n",
    "err_dev, thresh_dev = evaluate_EER_Thresh(genuine_scores_dev, impostor_scores_dev)\n",
    "\n",
    "\n",
    "#Ploteamos la curva ROC de los umbrales\n",
    "plotCurveROC ( genuine_scores_dev, impostor_scores_dev, title = \"ROC del modelo SVM con el dataset de validación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umbral de decisión global hallado (en formato score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.52927178)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respectiva tasa de error que nos daria el umbral de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08141386915029307"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723592</td>\n",
       "      <td>0.723592</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993043</td>\n",
       "      <td>0.993043</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.628710</td>\n",
       "      <td>0.628710</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956465</td>\n",
       "      <td>0.956465</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98681</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.048895</td>\n",
       "      <td>0.048895</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98682</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.297178</td>\n",
       "      <td>0.297178</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98683</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98684</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>genuine</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98685</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.744996</td>\n",
       "      <td>0.744996</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98686 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_model  user_id     score  std_score    y_test    y_pred\n",
       "0               1      1.0  0.723592   0.723592   genuine   genuine\n",
       "1               1      1.0  0.993043   0.993043   genuine   genuine\n",
       "2               1      1.0  0.995238   0.995238   genuine   genuine\n",
       "3               1      1.0  0.628710   0.628710   genuine   genuine\n",
       "4               1      1.0  0.956465   0.956465   genuine   genuine\n",
       "...           ...      ...       ...        ...       ...       ...\n",
       "98681         133    132.0  0.048895   0.048895  impostor  impostor\n",
       "98682         133    132.0  0.297178   0.297178  impostor  impostor\n",
       "98683         133    132.0  0.049806   0.049806  impostor  impostor\n",
       "98684         133    133.0  0.500000   0.500000   genuine  impostor\n",
       "98685         133    133.0  0.744996   0.744996   genuine   genuine\n",
       "\n",
       "[98686 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_evaluation_dev['y_pred'] = np.where(users_evaluation_dev['score'] >= thresh_dev, 'genuine', 'impostor')\n",
    "\n",
    "users_evaluation_dev.to_excel(\"./output/outputPredSVCDev.xlsx\")\n",
    "\n",
    "#Presentamos el calculo de resultados\n",
    "users_evaluation_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los y_test y y_pred de nuestros resultados\n",
    "y_test_dev = users_evaluation_dev.loc[:, \"y_test\"]\n",
    "y_pred_dev = users_evaluation_dev.loc[:, \"y_pred\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión del umbral hallado con el subdataset de desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9185902762296577"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_dev, y_pred_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del umbral usando el subdataset de PRUEBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_evaluation_test = []\n",
    "\n",
    "#Se hace el cálculo para cada usuario\n",
    "for subject in subjects:\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    #Generamos una copia temporal del dataset de entrenamiento\n",
    "    temp1 = train_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al sujeto actual por 0\n",
    "    temp1[\"user_id\"] = temp1[\"user_id\"].mask(temp1[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #Obtenemos los registros considerados genuinos del entrenamiento\n",
    "    genuine_data = temp1.loc[temp1.user_id == subject, :]\n",
    "\n",
    "    #Obtenemos los registros considerados impostores del entrenamiento.\n",
    "    #Este debe de ser del mismo tamaño que de los registros genuinos\n",
    "    impostor_data = temp1.loc[temp1.user_id != subject, :].sample(n= genuine_data.shape[0], random_state=43)\n",
    "\n",
    "    #Unimos los dos anteriores variables en un solo dataset de entrenamiento del modelo\n",
    "    train = pd.concat([genuine_data, impostor_data])\n",
    "\n",
    "    #Obtenemos el X_train\n",
    "    X_train = train.loc[:, \"ft_1\":\"ft_60\" ]\n",
    "\n",
    "    #Obtenemos el y_train\n",
    "    y_train = train.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Generamos una copia temporal del dataset de desarrollo\n",
    "    temp2 = dev_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp2[\"user_id\"] = temp2[\"user_id\"].mask(temp2[\"user_id\"] != subject, 0)\n",
    "\n",
    "    #df.sample(frac=0.5, replace=True, random_state=1)\n",
    "    X_dev = temp2.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_dev = temp2.loc[:, \"user_id\"]\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "\n",
    "    #Generamos una copia temporal del dataset de test\n",
    "    temp3 = test_users.copy()\n",
    "\n",
    "    #Reemplazamos todos los users_ids que son distintos al usuario 1 por 0\n",
    "    temp3[\"user_id\"] = temp3[\"user_id\"].mask(temp3[\"user_id\"] != subject, 0)\n",
    "\n",
    "    X_test = temp3.loc[:, \"ft_1\":\"ft_60\"]\n",
    "    y_test = temp3.loc[:, \"user_id\"]\n",
    "    \n",
    "    #----------------------------------------------------------------\n",
    "    \n",
    "    #Entrenamos el modelo SVM\n",
    "    \n",
    "    clf = SVC(C = 10.0, gamma = 'scale', kernel = 'rbf', probability = True, random_state=43)\n",
    "    #clf = SVC(probability = True)\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Obtenemos probabilidades de cada registro del dataset de test\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    y_prob = pd.DataFrame(y_prob, columns = [\"probImpos\", \"probLegi\"])\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    #Para cada registro del subdataset de test\n",
    "    for index, row in test_users.iterrows():\n",
    "\n",
    "        temp_obj = {}\n",
    "\n",
    "        #user id del registro actual del subdataset de test\n",
    "        current_user_id = row[0]\n",
    "\n",
    "        #Vector de tiempo del registro actual del subdataset de test\n",
    "        current_data = row[1:]\n",
    "\n",
    "        #Actual modelo del usuario a evaluar\n",
    "        temp_obj[\"user_model\"] = subject\n",
    "\n",
    "        #user id del registro actual\n",
    "        temp_obj[\"user_id\"] = current_user_id\n",
    "\n",
    "        #Puntaje o score del modelo\n",
    "        temp_obj[\"score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Normalizacion del score\n",
    "        temp_obj[\"std_score\"] = y_prob.iloc[i][\"probLegi\"]\n",
    "\n",
    "        #Variable que indica si el registro deberia de ser clasificado como genuino o impostor\n",
    "        if current_user_id == subject:\n",
    "            temp_obj[\"y_test\"] = \"genuine\"\n",
    "        else:\n",
    "            temp_obj[\"y_test\"] = \"impostor\"\n",
    "\n",
    "        users_evaluation_test.append(temp_obj)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "users_evaluation_test = pd.DataFrame(users_evaluation_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntaje de los registros del subdataset de test usando todos los modelos\n",
    " - **user_model:** modelo del usuario empleado para sacar el score\n",
    " - **user_id:** usuario del registro evaluado\n",
    " - **score:** puntuación que le dió el modelo\n",
    " - **std_score:** puntuación normalizada\n",
    " - **y_test:** cuando el user_model y user_id coinciden, entonces se usó un registro de usuario considerado genuino; caso contrario, es de un impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_model</th>\n",
       "      <th>user_id</th>\n",
       "      <th>score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984235</td>\n",
       "      <td>0.984235</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994690</td>\n",
       "      <td>0.994690</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984785</td>\n",
       "      <td>0.984785</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997429</td>\n",
       "      <td>0.997429</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108390</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.062821</td>\n",
       "      <td>0.062821</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108391</th>\n",
       "      <td>133</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.018058</td>\n",
       "      <td>0.018058</td>\n",
       "      <td>impostor</td>\n",
       "      <td>impostor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108392</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.838647</td>\n",
       "      <td>0.838647</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108393</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.944967</td>\n",
       "      <td>0.944967</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108394</th>\n",
       "      <td>133</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.973146</td>\n",
       "      <td>0.973146</td>\n",
       "      <td>genuine</td>\n",
       "      <td>genuine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108395 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_model  user_id     score  std_score    y_test    y_pred\n",
       "0                1      1.0  0.999992   0.999992   genuine   genuine\n",
       "1                1      1.0  0.984235   0.984235   genuine   genuine\n",
       "2                1      1.0  0.994690   0.994690   genuine   genuine\n",
       "3                1      1.0  0.984785   0.984785   genuine   genuine\n",
       "4                1      1.0  0.997429   0.997429   genuine   genuine\n",
       "...            ...      ...       ...        ...       ...       ...\n",
       "108390         133    132.0  0.062821   0.062821  impostor  impostor\n",
       "108391         133    132.0  0.018058   0.018058  impostor  impostor\n",
       "108392         133    133.0  0.838647   0.838647   genuine   genuine\n",
       "108393         133    133.0  0.944967   0.944967   genuine   genuine\n",
       "108394         133    133.0  0.973146   0.973146   genuine   genuine\n",
       "\n",
       "[108395 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OJO, aca se esta usando el score como umbral, si usaramos el score estandarizado, deberiamos de cambiar el sentido de la comparación\n",
    "users_evaluation_test['y_pred'] = np.where(users_evaluation_test['score'] >= thresh_dev, 'genuine', 'impostor')\n",
    "\n",
    "users_evaluation_test.to_excel(\"./output/outputPredSVCTest.xlsx\")\n",
    "\n",
    "#Presentamos el calculo de resultados\n",
    "users_evaluation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los y_test y y_pred de nuestros resultados\n",
    "y_test_test = users_evaluation_test.loc[:, \"y_test\"]\n",
    "y_pred_test = users_evaluation_test.loc[:, \"y_pred\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "### Precisión del umbral hallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9185663545366484"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como genuinos por los modelos\n",
    "genuine_scores_test = list(users_evaluation_test.loc[users_evaluation_test.y_test == \"genuine\", \"score\"])\n",
    "\n",
    "#Obtenemos la listas de scores de los registros que deberian de catalogarse como impostores por los modelos\n",
    "impostor_scores_test = list(users_evaluation_test.loc[users_evaluation_test.y_test == \"impostor\", \"score\"])\n",
    "\n",
    "thresh_x, thresh_y, _ = find_fpr_and_tpr_given_a_threshold(genuine_scores_test, impostor_scores_test, thresh_dev)\n",
    "\n",
    "thresh_std = round(thresh_dev.tolist(), 3)\n",
    "\n",
    "#Ploteamos la curva ROC\n",
    "plotCurveROC_Threshold( genuine_scores_test, impostor_scores_test, thresh_std, thresh_x, thresh_y, \"black\",  title = \"ROC del modelo SVM con el dataset de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"SVM - Modelo Usuario 1\")\n",
    "\n",
    "sc1 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 1), \"std_score\"]\n",
    "sc2 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 2), \"std_score\"]\n",
    "sc3 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 3), \"std_score\"]\n",
    "sc4 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 1) & (users_evaluation_dev.user_id == 4), \"std_score\"]\n",
    "\n",
    "y1 = np.zeros(len(sc1))\n",
    "y2 = np.zeros(len(sc2))\n",
    "y3 = np.zeros(len(sc3))\n",
    "y4 = np.zeros(len(sc4))\n",
    "\n",
    "plt.scatter(sc1, y1, label = \"Usuario 1\")\n",
    "plt.scatter(sc2, y2, label = \"Usuario 2\")\n",
    "plt.scatter(sc3, y3, label = \"Usuario 3\")\n",
    "plt.scatter(sc4, y4, label = \"Usuario 4\")\n",
    "\n",
    "plt.plot(0.52927178, 0, marker= \"|\", color = \"blacK\", markersize= 25)\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"SVM - Modelo Usuario 2\")\n",
    "\n",
    "sc1 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 1), \"std_score\"]\n",
    "sc2 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 2), \"std_score\"]\n",
    "sc3 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 3), \"std_score\"]\n",
    "sc4 = users_evaluation_dev.loc[(users_evaluation_dev.user_model == 2) & (users_evaluation_dev.user_id == 4), \"std_score\"]\n",
    "\n",
    "y1 = np.zeros(len(sc1))\n",
    "y2 = np.zeros(len(sc2))\n",
    "y3 = np.zeros(len(sc3))\n",
    "y4 = np.zeros(len(sc4))\n",
    "\n",
    "plt.scatter(sc2, y2, label = \"Usuario 2\")\n",
    "plt.scatter(sc1, y1, label = \"Usuario 1\")\n",
    "plt.scatter(sc3, y3, label = \"Usuario 3\")\n",
    "plt.scatter(sc4, y4, label = \"Usuario 4\")\n",
    "\n",
    "plt.plot(0.52927178, 0, marker= \"|\", color = \"blacK\", markersize= 25)\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.min()[\"score\"]\n",
    "\n",
    "'{0:.0f}'.format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.max()[\"score\"]\n",
    "\n",
    "'{0:.0f}'.format(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00000108'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.min()[\"std_score\"]\n",
    "\n",
    "'{0:.8f}'.format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.99999994'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = users_evaluation_test.max()[\"std_score\"]\n",
    "\n",
    "'{0:.8f}'.format(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['age_bmi'] = df.age * df.bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar excel\n",
    "#users_evaluation.to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.calibration import CalibratedClassifierCV\\n\\nisotonic_svc = CalibratedClassifierCV(\\n    base_estimator=SVC(kernel='linear', probability= False, random_state= 43),\\n    method='isotonic', cv= 5\\n) # isotonic calibration\\n\\nisotonic_svc.fit(X_train, y_train)\\ny_prob2 = isotonic_svc.predict_proba(X_dev)\\ny_prob2\\n\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "isotonic_svc = CalibratedClassifierCV(\n",
    "    base_estimator=SVC(kernel='linear', probability= False, random_state= 43),\n",
    "    method='isotonic', cv= 5\n",
    ") # isotonic calibration\n",
    "\n",
    "isotonic_svc.fit(X_train, y_train)\n",
    "y_prob2 = isotonic_svc.predict_proba(X_dev)\n",
    "y_prob2\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
